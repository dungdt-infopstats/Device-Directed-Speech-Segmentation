{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12932733,
          "sourceType": "datasetVersion",
          "datasetId": 8183808
        },
        {
          "sourceId": 12938348,
          "sourceType": "datasetVersion",
          "datasetId": 8187428
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "WER-COMPUTATION",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dungdt-infopstats/TV-command-synthesis/blob/main/notebooks/WER_COMPUTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "s5HdV1cPUu3Y"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "tridungdo_ddss_aug_ratio_test_path = kagglehub.dataset_download('tridungdo/ddss-aug-ratio-test')\n",
        "tridungdo_res_analysis_test_res_json_path = kagglehub.dataset_download('tridungdo/res-analysis-test-res-json')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CRocyJBhUu3b"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 10uHbeqAO5uqOQV6eOXnTuS150MEUTDdk"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:02:26.944995Z",
          "iopub.execute_input": "2025-09-02T17:02:26.94526Z",
          "iopub.status.idle": "2025-09-02T17:02:49.586254Z",
          "shell.execute_reply.started": "2025-09-02T17:02:26.945234Z",
          "shell.execute_reply": "2025-09-02T17:02:49.585547Z"
        },
        "id": "H4I1IeU9Uu3c",
        "outputId": "dae13931-da7a-41f4-be65-09fb520e5dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading...\nFrom (original): https://drive.google.com/uc?id=10uHbeqAO5uqOQV6eOXnTuS150MEUTDdk\nFrom (redirected): https://drive.google.com/uc?id=10uHbeqAO5uqOQV6eOXnTuS150MEUTDdk&confirm=t&uuid=47472f0c-c125-41d6-af66-f448d9cb18ff\nTo: /kaggle/working/synthesis.zip\n100%|████████████████████████████████████████| 955M/955M [00:19<00:00, 49.0MB/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q synthesis.zip"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:02:49.587328Z",
          "iopub.execute_input": "2025-09-02T17:02:49.587605Z",
          "iopub.status.idle": "2025-09-02T17:02:55.776619Z",
          "shell.execute_reply.started": "2025-09-02T17:02:49.587569Z",
          "shell.execute_reply": "2025-09-02T17:02:55.775815Z"
        },
        "id": "y9LUgi_uUu3d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for file in os.listdir('synthesis'):\n",
        "    path = f\"synthesis/{file}\"\n",
        "    !unzip -q {path} -d command_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:02:55.778565Z",
          "iopub.execute_input": "2025-09-02T17:02:55.778889Z",
          "iopub.status.idle": "2025-09-02T17:03:13.739851Z",
          "shell.execute_reply.started": "2025-09-02T17:02:55.778864Z",
          "shell.execute_reply": "2025-09-02T17:03:13.739021Z"
        },
        "id": "94RN34yjUu3d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "list_row = []\n",
        "for folder in os.listdir('command_text'):\n",
        "    for file in os.listdir(os.path.join('command_text', folder)):\n",
        "        if file.endswith('.json'):\n",
        "            with open(os.path.join('command_text', folder, file)) as f:\n",
        "                data = json.load(f)\n",
        "                id_f = folder\n",
        "                data['id'] = id_f\n",
        "                list_row.append(data)\n",
        "\n",
        "\n",
        "df_text = pd.DataFrame(list_row)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:13.74077Z",
          "iopub.execute_input": "2025-09-02T17:03:13.740969Z",
          "iopub.status.idle": "2025-09-02T17:03:14.207505Z",
          "shell.execute_reply.started": "2025-09-02T17:03:13.740948Z",
          "shell.execute_reply": "2025-09-02T17:03:14.206953Z"
        },
        "id": "53LCOWFJUu3d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_text['text_active'] = None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:14.208202Z",
          "iopub.execute_input": "2025-09-02T17:03:14.208666Z",
          "iopub.status.idle": "2025-09-02T17:03:16.959044Z",
          "shell.execute_reply.started": "2025-09-02T17:03:14.208645Z",
          "shell.execute_reply": "2025-09-02T17:03:16.958264Z"
        },
        "id": "OlcbZGebUu3e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in df_text.iterrows():\n",
        "    if row['type'] == 'non_active':\n",
        "        df_text.loc[idx, 'text_active'] = None\n",
        "    elif row['num_segments'] == 0:\n",
        "        df_text.loc[idx, 'text_active'] = row['command']\n",
        "    else:\n",
        "        active_list = []\n",
        "        for i in range(row['num_segments']):\n",
        "            if row['type_segments'][str(i)] == 'active':\n",
        "                active_list.append(row['text_segments'][str(i)])\n",
        "\n",
        "        text = \" \".join(active_list)\n",
        "        df_text.loc[idx, 'text_active'] = text\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:16.959897Z",
          "iopub.execute_input": "2025-09-02T17:03:16.960147Z",
          "iopub.status.idle": "2025-09-02T17:03:17.495208Z",
          "shell.execute_reply.started": "2025-09-02T17:03:16.960125Z",
          "shell.execute_reply": "2025-09-02T17:03:17.494416Z"
        },
        "id": "wpXmsiPBUu3e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/kaggle/input/res-analysis-test-res-json/res_analysis.json\") as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:17.496288Z",
          "iopub.execute_input": "2025-09-02T17:03:17.496481Z",
          "iopub.status.idle": "2025-09-02T17:03:23.123385Z",
          "shell.execute_reply.started": "2025-09-02T17:03:17.496465Z",
          "shell.execute_reply": "2025-09-02T17:03:23.122544Z"
        },
        "id": "KZFX8pyjUu3e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_analysis = pd.DataFrame(data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:23.124243Z",
          "iopub.execute_input": "2025-09-02T17:03:23.124936Z",
          "iopub.status.idle": "2025-09-02T17:03:23.180253Z",
          "shell.execute_reply.started": "2025-09-02T17:03:23.12489Z",
          "shell.execute_reply": "2025-09-02T17:03:23.179711Z"
        },
        "id": "Yu1-stOCUu3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_analysis['id_f'] = data_analysis['id'].str.rsplit(pat=\"_\", n=1).str[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:23.182548Z",
          "iopub.execute_input": "2025-09-02T17:03:23.182763Z",
          "iopub.status.idle": "2025-09-02T17:03:23.201586Z",
          "shell.execute_reply.started": "2025-09-02T17:03:23.182746Z",
          "shell.execute_reply": "2025-09-02T17:03:23.20069Z"
        },
        "id": "kVA3fu7TUu3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "merge = pd.merge(data_analysis, df_text, left_on = 'id_f', right_on = 'id')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:23.202195Z",
          "iopub.execute_input": "2025-09-02T17:03:23.202425Z",
          "iopub.status.idle": "2025-09-02T17:03:23.247491Z",
          "shell.execute_reply.started": "2025-09-02T17:03:23.202408Z",
          "shell.execute_reply": "2025-09-02T17:03:23.246689Z"
        },
        "id": "nXCacFSTUu3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install pydub\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:03:23.248304Z",
          "iopub.execute_input": "2025-09-02T17:03:23.248557Z",
          "iopub.status.idle": "2025-09-02T17:03:46.13092Z",
          "shell.execute_reply.started": "2025-09-02T17:03:23.248535Z",
          "shell.execute_reply": "2025-09-02T17:03:46.130196Z"
        },
        "id": "l3BPvFdtUu3f",
        "outputId": "ebaaf08f-c4e6-4c68-ad63-2e5c9d50ea28"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting faster-whisper\n  Downloading faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)\nCollecting ctranslate2<5,>=4.0 (from faster-whisper)\n  Downloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.33.1)\nRequirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.2)\nCollecting onnxruntime<2,>=1.14 (from faster-whisper)\n  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nCollecting av>=11 (from faster-whisper)\n  Downloading av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.67.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\nRequirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.5)\nCollecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.6.15)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\nDownloading faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hDownloading av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, av, coloredlogs, onnxruntime, ctranslate2, faster-whisper\nSuccessfully installed av-15.1.0 coloredlogs-15.0.1 ctranslate2-4.6.0 faster-whisper-1.2.0 humanfriendly-10.0 onnxruntime-1.22.1\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nCollecting jiwer\n  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.14.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\nDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\nDownloading rapidfuzz-3.14.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-4.0.0 rapidfuzz-3.14.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from pydub import AudioSegment\n",
        "import jiwer\n",
        "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "import threading\n",
        "from functools import partial\n",
        "import ast\n",
        "\n",
        "# ==========================================================\n",
        "# Helper: Convert vector -> time ranges\n",
        "# ==========================================================\n",
        "def vector_to_time_ranges(\n",
        "    vector: List[int],\n",
        "    frame_dur: float,\n",
        "    hop_dur: float,\n",
        "    pad: int = 1\n",
        ") -> List[Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Convert binary vector (0/1) -> list of {\"start\", \"end\"} in seconds.\n",
        "    Merge segments when short gaps exist (controlled by pad).\n",
        "    \"\"\"\n",
        "    ranges = []\n",
        "    n = len(vector)\n",
        "    i = 0\n",
        "\n",
        "    while i < n:\n",
        "        if vector[i] == 1:\n",
        "            start = i * hop_dur\n",
        "            j = i\n",
        "            while j < n and any(vector[max(0, j - pad):min(n, j + pad + 1)]):\n",
        "                j += 1\n",
        "            end = j * hop_dur + frame_dur\n",
        "            ranges.append({\"start\": start, \"end\": end})\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return ranges\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Helper: Load audio and slice\n",
        "# ==========================================================\n",
        "def load_audio_as_pydub(path: str, sr: Optional[int] = None) -> AudioSegment:\n",
        "    \"\"\"Load audio file using pydub with optional sample rate conversion.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Audio file not found: {path}\")\n",
        "\n",
        "    audio = AudioSegment.from_file(path)\n",
        "    if sr is not None and audio.frame_rate != sr:\n",
        "        audio = audio.set_frame_rate(sr)\n",
        "    return audio\n",
        "\n",
        "def slice_audio_segment(audio: AudioSegment, start: float, end: float) -> AudioSegment:\n",
        "    \"\"\"Slice audio segment from start to end (in seconds).\"\"\"\n",
        "    start_ms = max(0, int(start * 1000))\n",
        "    end_ms = min(len(audio), int(end * 1000))\n",
        "    return audio[start_ms:end_ms]\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Helper: Alignment & WER (Fixed jiwer usage)\n",
        "# ==========================================================\n",
        "def levenshtein_alignment(ref: str, hyp: str) -> Dict[str, Any]:\n",
        "    \"\"\"Compute WER and alignment statistics using jiwer.\"\"\"\n",
        "    try:\n",
        "        # Clean text first\n",
        "        ref = ref.strip() if ref else \"\"\n",
        "        hyp = hyp.strip() if hyp else \"\"\n",
        "\n",
        "        if not ref and not hyp:\n",
        "            return {\"wer\": 0.0, \"S\": 0, \"D\": 0, \"I\": 0, \"N\": 0}\n",
        "        elif not ref:\n",
        "            return {\"wer\": 1.0, \"S\": 0, \"D\": 0, \"I\": len(hyp.split()), \"N\": 0}\n",
        "        elif not hyp:\n",
        "            return {\"wer\": 1.0, \"S\": 0, \"D\": len(ref.split()), \"I\": 0, \"N\": len(ref.split())}\n",
        "\n",
        "        # Use the correct jiwer API\n",
        "        wer_score = jiwer.wer(ref, hyp)\n",
        "\n",
        "        # Get detailed measures using jiwer process_words\n",
        "        measures = jiwer.process_words(ref, hyp)\n",
        "\n",
        "        return {\n",
        "            \"wer\": wer_score,\n",
        "            \"S\": measures.substitutions,\n",
        "            \"D\": measures.deletions,\n",
        "            \"I\": measures.insertions,\n",
        "            \"N\": measures.hits + measures.substitutions + measures.deletions,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in WER computation for ref='{ref}', hyp='{hyp}': {e}\")\n",
        "        return {\n",
        "            \"wer\": 1.0,\n",
        "            \"S\": 0,\n",
        "            \"D\": len(ref.split()) if ref else 0,\n",
        "            \"I\": len(hyp.split()) if hyp else 0,\n",
        "            \"N\": len(ref.split()) if ref else 0,\n",
        "        }\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Helper function for safe metadata copying\n",
        "# ==========================================================\n",
        "def safe_copy_metadata(df_segments: pd.DataFrame, row: pd.Series, original_columns: List[str]) -> pd.DataFrame:\n",
        "    \"\"\"Safely copy metadata from original row to segments DataFrame.\"\"\"\n",
        "    if df_segments.empty:\n",
        "        return df_segments\n",
        "\n",
        "    for col in original_columns:\n",
        "        if col not in df_segments.columns:\n",
        "            try:\n",
        "                value = row[col]\n",
        "                # Handle different data types safely\n",
        "                if isinstance(value, (list, np.ndarray)):\n",
        "                    # Convert to string representation for complex data\n",
        "                    value = str(value)\n",
        "                elif pd.isna(value):\n",
        "                    value = None\n",
        "\n",
        "                # Assign scalar value to all rows\n",
        "                df_segments[col] = value\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not copy column '{col}': {e}\")\n",
        "                df_segments[col] = None\n",
        "\n",
        "    return df_segments\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Thread-safe Whisper Model Manager\n",
        "# ==========================================================\n",
        "class WhisperModelManager:\n",
        "    \"\"\"Thread-safe manager for Whisper models.\"\"\"\n",
        "\n",
        "    def __init__(self, model_size=\"medium\", device=\"cpu\", max_workers=4):\n",
        "        self.model_size = model_size\n",
        "        self.device = device\n",
        "        self.max_workers = max_workers\n",
        "        self._models = {}\n",
        "        self._lock = threading.Lock()\n",
        "\n",
        "    def get_model(self, thread_id: int) -> WhisperModel:\n",
        "        \"\"\"Get or create a model for the current thread.\"\"\"\n",
        "        with self._lock:\n",
        "            if thread_id not in self._models:\n",
        "                model = WhisperModel(self.model_size, device=self.device)\n",
        "                self._models[thread_id] = model\n",
        "\n",
        "            return self._models[thread_id]\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Processor class with multi-threading support\n",
        "# ==========================================================\n",
        "class ASRProcessor:\n",
        "    def __init__(self, model_size=\"medium\", device=\"cpu\", max_workers=4):\n",
        "        self.model_manager = WhisperModelManager(model_size, device, max_workers)\n",
        "        self.max_workers = max_workers\n",
        "\n",
        "    def transcribe_segment(self, audio: AudioSegment, thread_id: int, batch_mode = True) -> str:\n",
        "        \"\"\"Transcribe a single audio segment.\"\"\"\n",
        "        model = self.model_manager.get_model(thread_id)\n",
        "        if batch_mode:\n",
        "            model = BatchedInferencePipeline(model = model)\n",
        "        # Create temporary file for this segment\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
        "            tmp_path = tmp_file.name\n",
        "\n",
        "        try:\n",
        "            # Export audio segment to temporary file\n",
        "            audio.export(tmp_path, format=\"wav\")\n",
        "\n",
        "            # Transcribe using Whisper\n",
        "            if not batch_mode:\n",
        "                segments, _ = model.transcribe(tmp_path)\n",
        "            else:\n",
        "                segments, _ = model.transcribe(tmp_path, batch_size = 128)\n",
        "            text = \" \".join([seg.text for seg in segments]).strip()\n",
        "\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing segment: {e}\")\n",
        "            return \"\"\n",
        "        finally:\n",
        "            # Clean up temporary file\n",
        "            if os.path.exists(tmp_path):\n",
        "                os.unlink(tmp_path)\n",
        "\n",
        "    def process_segment(\n",
        "        self,\n",
        "        args: Tuple[AudioSegment, Dict[str, float], int, Optional[str], int]\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Process a single segment (for threading).\"\"\"\n",
        "        audio_seg, time_range, idx, reference_text, thread_id = args\n",
        "\n",
        "        # Slice audio\n",
        "        seg = slice_audio_segment(audio_seg, time_range[\"start\"], time_range[\"end\"])\n",
        "\n",
        "        # Check if segment is too short\n",
        "        if len(seg) < 100:  # Less than 0.1 second\n",
        "            return {\n",
        "                \"segment_index\": idx,\n",
        "                \"start\": time_range[\"start\"],\n",
        "                \"end\": time_range[\"end\"],\n",
        "                \"recognized_text\": \"\",\n",
        "                \"reference_text\": reference_text if reference_text else \"\",\n",
        "                \"wer\": 1.0 if reference_text else 0.0,\n",
        "                \"S\": 0,\n",
        "                \"D\": len(reference_text.split()) if reference_text else 0,\n",
        "                \"I\": 0,\n",
        "                \"N\": len(reference_text.split()) if reference_text else 0,\n",
        "            }\n",
        "\n",
        "        # Transcribe\n",
        "        hyp = self.transcribe_segment(seg, thread_id)\n",
        "\n",
        "        # Prepare result\n",
        "        result = {\n",
        "            \"segment_index\": idx,\n",
        "            \"start\": time_range[\"start\"],\n",
        "            \"end\": time_range[\"end\"],\n",
        "            \"recognized_text\": hyp,\n",
        "        }\n",
        "\n",
        "        # Compute WER if reference text is provided\n",
        "        if reference_text:\n",
        "            align = levenshtein_alignment(reference_text, hyp)\n",
        "            result.update({\n",
        "                \"reference_text\": reference_text,\n",
        "                \"wer\": align[\"wer\"],\n",
        "                \"S\": align[\"S\"],\n",
        "                \"D\": align[\"D\"],\n",
        "                \"I\": align[\"I\"],\n",
        "                \"N\": align[\"N\"],\n",
        "            })\n",
        "\n",
        "        return result\n",
        "\n",
        "    def process_file(\n",
        "        self,\n",
        "        audio_path: str,\n",
        "        sr: Optional[int],\n",
        "        vector: List[int],\n",
        "        frame_dur: float,\n",
        "        hop_dur: float,\n",
        "        pad: int,\n",
        "        reference_texts: Optional[str] = None,\n",
        "        show_progress: bool = True,\n",
        "        fallback_on_no_segments: bool = True,\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Process one audio file: slice segments by vector, run ASR with multi-threading, compute WER.\n",
        "        If fallback_on_no_segments=True, will create a fallback result with empty text when no segments found.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load audio\n",
        "            audio_seg = load_audio_as_pydub(audio_path, sr)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading audio {audio_path}: {e}\")\n",
        "            # Return fallback result regardless of reference text\n",
        "            if fallback_on_no_segments:\n",
        "                ref_text = reference_texts if reference_texts else \"\"\n",
        "                return self._create_fallback_result(ref_text, \"file_load_error\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        time_ranges = vector_to_time_ranges(vector, frame_dur, hop_dur, pad)\n",
        "\n",
        "        # If no segments found, create fallback result\n",
        "        if not time_ranges:\n",
        "            print(f\"No active segments found for {audio_path}\")\n",
        "            if fallback_on_no_segments:\n",
        "                # Create fallback even if no reference text\n",
        "                ref_text = reference_texts if reference_texts else \"\"\n",
        "                return self._create_fallback_result(ref_text, \"no_segments\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Prepare arguments for threading\n",
        "        args_list = [\n",
        "            (audio_seg, time_range, idx, reference_texts, idx % self.max_workers)\n",
        "            for idx, time_range in enumerate(time_ranges)\n",
        "        ]\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Process segments with threading\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            # Submit all tasks\n",
        "            future_to_args = {\n",
        "                executor.submit(self.process_segment, args): args\n",
        "                for args in args_list\n",
        "            }\n",
        "\n",
        "            # Collect results with progress bar\n",
        "            if show_progress:\n",
        "                pbar = tqdm(total=len(args_list), desc=f\"Processing segments from {os.path.basename(audio_path)}\")\n",
        "\n",
        "            for future in as_completed(future_to_args):\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "                    if show_progress:\n",
        "                        pbar.update(1)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing segment: {e}\")\n",
        "                    if show_progress:\n",
        "                        pbar.update(1)\n",
        "\n",
        "            if show_progress:\n",
        "                pbar.close()\n",
        "\n",
        "        # Sort results by segment index\n",
        "        results.sort(key=lambda x: x[\"segment_index\"])\n",
        "\n",
        "        # If no valid segments processed, create fallback result\n",
        "        if not results:\n",
        "            print(f\"No valid segments processed for {audio_path}\")\n",
        "            if fallback_on_no_segments:\n",
        "                # Create fallback even if no reference text\n",
        "                ref_text = reference_texts if reference_texts else \"\"\n",
        "                return self._create_fallback_result(ref_text, \"processing_failed\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def _create_fallback_result(self, reference_text: str, reason: str = \"no_segments\") -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Create a fallback result when no segments are found but we still want to compute WER.\n",
        "        Assumes empty hypothesis (no recognized text).\n",
        "\n",
        "        Logic:\n",
        "        - If reference is empty/null and hypothesis is empty -> WER = 0 (perfect match)\n",
        "        - If reference has content and hypothesis is empty -> WER = 1 (complete failure)\n",
        "        \"\"\"\n",
        "        # Clean reference text\n",
        "        ref_clean = reference_text.strip() if reference_text else \"\"\n",
        "\n",
        "        # Compute WER with empty hypothesis\n",
        "        align = levenshtein_alignment(ref_clean, \"\")\n",
        "\n",
        "        result = {\n",
        "            \"segment_index\": 0,\n",
        "            \"start\": 0.0,\n",
        "            \"end\": 0.0,\n",
        "            \"recognized_text\": \"\",\n",
        "            \"reference_text\": ref_clean,\n",
        "            \"wer\": align[\"wer\"],  # Will be 0 if both ref and hyp are empty\n",
        "            \"S\": align[\"S\"],\n",
        "            \"D\": align[\"D\"],\n",
        "            \"I\": align[\"I\"],\n",
        "            \"N\": align[\"N\"],\n",
        "            \"fallback_reason\": reason  # Track why this was a fallback\n",
        "        }\n",
        "\n",
        "        return pd.DataFrame([result])\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Safe parsing function\n",
        "# ==========================================================\n",
        "def safe_parse_predictions(preds_str: str) -> Optional[List[int]]:\n",
        "    \"\"\"Safely parse predictions string to list.\"\"\"\n",
        "    try:\n",
        "        if isinstance(preds_str, list):\n",
        "            return preds_str\n",
        "        if isinstance(preds_str, str):\n",
        "            # Try ast.literal_eval first (safer than eval)\n",
        "            try:\n",
        "                return ast.literal_eval(preds_str)\n",
        "            except:\n",
        "                # Fallback to eval if needed\n",
        "                return eval(preds_str)\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing predictions: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Process DataFrame template with multi-threading\n",
        "# ==========================================================\n",
        "def process_from_template_df(\n",
        "    df: pd.DataFrame,\n",
        "    model_size: str = \"medium\",\n",
        "    device: str = \"cpu\",\n",
        "    frame_dur: float = 0.02,\n",
        "    hop_dur: float = 0.01,\n",
        "    pad: int = 2,\n",
        "    max_workers: int = 4,\n",
        "    audio_root_path: str = \"/kaggle/input/ddss-aug-ratio-test/test\",\n",
        "    fallback_on_no_segments: bool = True\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process dataset from a template DataFrame with columns:\n",
        "      - id_x: unique id (map to audio path)\n",
        "      - id_f: folder name\n",
        "      - preds: binary vector\n",
        "      - text_active: reference text for WER\n",
        "\n",
        "    Returns: DataFrame with per-segment evaluation metrics, merged with original metadata.\n",
        "    \"\"\"\n",
        "    print(f\"Initializing ASR Processor with model_size={model_size}, device={device}, max_workers={max_workers}\")\n",
        "    processor = ASRProcessor(model_size=model_size, device=device, max_workers=max_workers)\n",
        "    all_results = []\n",
        "\n",
        "    print(f\"Processing {len(df)} files...\")\n",
        "\n",
        "    # Process each row with progress bar\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing files\"):\n",
        "        try:\n",
        "            # Resolve audio path\n",
        "            audio_id = row[\"id_x\"]\n",
        "            folder_name = row.get(\"id_f\", \"\")\n",
        "            audio_path = os.path.join(audio_root_path, folder_name, f\"{audio_id}.wav\")\n",
        "\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(f\"Warning: Audio file not found: {audio_path}\")\n",
        "                continue\n",
        "\n",
        "            # Parse predictions vector safely\n",
        "            preds = safe_parse_predictions(row[\"preds\"])\n",
        "            if preds is None:\n",
        "                print(f\"Error parsing predictions for {audio_id}\")\n",
        "                continue\n",
        "\n",
        "            # Get reference text (can be None/empty)\n",
        "            ref_text = row.get(\"text_active\", None)\n",
        "            if pd.isna(ref_text):\n",
        "                ref_text = None\n",
        "\n",
        "            # Process file with ASR + WER\n",
        "            df_segments = processor.process_file(\n",
        "                audio_path=audio_path,\n",
        "                sr=row.get(\"sampling_rate\", None),\n",
        "                vector=preds,\n",
        "                frame_dur=frame_dur,\n",
        "                hop_dur=hop_dur,\n",
        "                pad=pad,\n",
        "                reference_texts=ref_text,\n",
        "                show_progress=False,  # Don't show segment progress for each file\n",
        "                fallback_on_no_segments=fallback_on_no_segments\n",
        "            )\n",
        "\n",
        "            if df_segments.empty:\n",
        "                print(f\"No segments processed for {audio_id}\")\n",
        "                continue\n",
        "\n",
        "            # Copy original metadata to all segments using safe function\n",
        "            df_segments = safe_copy_metadata(df_segments, row, df.columns.tolist())\n",
        "\n",
        "            all_results.append(df_segments)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {idx} (id={row.get('id_x', 'unknown')}): {e}\")\n",
        "            continue\n",
        "\n",
        "    if not all_results:\n",
        "        print(\"Warning: No results to concatenate\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Concatenating results from {len(all_results)} processed files...\")\n",
        "    final_df = pd.concat(all_results, ignore_index=True)\n",
        "    print(f\"Final dataset shape: {final_df.shape}\")\n",
        "\n",
        "    return final_df\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Utility functions for analysis\n",
        "# ==========================================================\n",
        "def compute_summary_stats(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "    \"\"\"Compute summary statistics from results DataFrame.\"\"\"\n",
        "    if df.empty or 'wer' not in df.columns:\n",
        "        return {}\n",
        "\n",
        "    # Filter out invalid WER values\n",
        "    valid_wer = df[df['wer'].notna() & (df['wer'] >= 0)]\n",
        "\n",
        "    if valid_wer.empty:\n",
        "        return {\"message\": \"No valid WER scores found\"}\n",
        "\n",
        "    # Count fallback results\n",
        "    fallback_count = len(df[df.get('fallback_reason', '').notna()]) if 'fallback_reason' in df.columns else 0\n",
        "    normal_segments = len(df) - fallback_count\n",
        "\n",
        "    stats = {\n",
        "        \"total_segments\": len(df),\n",
        "        \"normal_segments\": normal_segments,\n",
        "        \"fallback_segments\": fallback_count,\n",
        "        \"valid_segments\": len(valid_wer),\n",
        "        \"mean_wer\": valid_wer[\"wer\"].mean(),\n",
        "        \"median_wer\": valid_wer[\"wer\"].median(),\n",
        "        \"std_wer\": valid_wer[\"wer\"].std(),\n",
        "        \"min_wer\": valid_wer[\"wer\"].min(),\n",
        "        \"max_wer\": valid_wer[\"wer\"].max(),\n",
        "        \"total_substitutions\": df[\"S\"].sum() if \"S\" in df.columns else 0,\n",
        "        \"total_deletions\": df[\"D\"].sum() if \"D\" in df.columns else 0,\n",
        "        \"total_insertions\": df[\"I\"].sum() if \"I\" in df.columns else 0,\n",
        "        \"total_words\": df[\"N\"].sum() if \"N\" in df.columns else 0,\n",
        "    }\n",
        "\n",
        "    # Add fallback breakdown if there are fallback results\n",
        "    if fallback_count > 0 and 'fallback_reason' in df.columns:\n",
        "        fallback_reasons = df[df['fallback_reason'].notna()]['fallback_reason'].value_counts().to_dict()\n",
        "        stats[\"fallback_breakdown\"] = fallback_reasons\n",
        "\n",
        "    return stats\n",
        "\n",
        "\n",
        "def save_results(df: pd.DataFrame, output_path: str, include_summary: bool = True):\n",
        "    \"\"\"Save results to file with optional summary statistics.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"Warning: DataFrame is empty, nothing to save\")\n",
        "        return\n",
        "\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "\n",
        "    if include_summary:\n",
        "        summary = compute_summary_stats(df)\n",
        "        if summary:\n",
        "            summary_path = output_path.replace('.csv', '_summary.txt')\n",
        "            with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(\"ASR Evaluation Summary\\n\")\n",
        "                f.write(\"=\" * 25 + \"\\n\")\n",
        "                for key, value in summary.items():\n",
        "                    f.write(f\"{key}: {value}\\n\")\n",
        "            print(f\"Summary statistics saved to: {summary_path}\")\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Main execution\n",
        "# ==========================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Assume 'merge' DataFrame exists and has the required columns\n",
        "    # You would need to define or load your 'merge' DataFrame here\n",
        "\n",
        "    try:\n",
        "        # Process with multi-threading\n",
        "        print(\"Starting ASR evaluation...\")\n",
        "        results_df = process_from_template_df(\n",
        "            df=merge,  # Make sure this variable is defined\n",
        "            model_size=\"base\",  # Use smaller model for faster processing\n",
        "            device=\"cuda\",\n",
        "            max_workers=4,\n",
        "            audio_root_path=\"/kaggle/input/ddss-aug-ratio-test/test\",\n",
        "            fallback_on_no_segments=True  # Enable fallback for files with no segments\n",
        "        )\n",
        "\n",
        "        # Save results\n",
        "        if not results_df.empty:\n",
        "            save_results(results_df, \"asr_evaluation_results.csv\")\n",
        "\n",
        "            # Print summary\n",
        "            summary = compute_summary_stats(results_df)\n",
        "            print(\"\\nSummary Statistics:\")\n",
        "            print(\"=\" * 20)\n",
        "            for key, value in summary.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "        else:\n",
        "            print(\"No results to save.\")\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Make sure the 'merge' DataFrame is defined before running this script.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-02T17:15:20.982338Z",
          "iopub.execute_input": "2025-09-02T17:15:20.982698Z",
          "iopub.status.idle": "2025-09-02T17:15:37.396719Z",
          "shell.execute_reply.started": "2025-09-02T17:15:20.982675Z",
          "shell.execute_reply": "2025-09-02T17:15:37.3956Z"
        },
        "id": "qNZA1B8MUu3f",
        "outputId": "51e2f80f-8afd-4814-de9a-738bd0a7f46e",
        "colab": {
          "referenced_widgets": [
            "b66f5b53a71c45ceb9c271978c00e9e7",
            "62ac78d3de7840f881529648b6b85f07",
            "6bd6f47e3ff94e8a91b09fb155486e59",
            "3fcdb8db11634c28854b3e020a6b9337"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting ASR evaluation...\nInitializing ASR Processor with model_size=base, device=cuda, max_workers=4\nProcessing 15834 files...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing files:   0%|          | 0/15834 [00:00<?, ?it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b66f5b53a71c45ceb9c271978c00e9e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocabulary.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62ac78d3de7840f881529648b6b85f07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bd6f47e3ff94e8a91b09fb155486e59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.bin:   0%|          | 0.00/145M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fcdb8db11634c28854b3e020a6b9337"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Processing files:   0%|          | 24/15834 [00:16<2:59:12,  1.47it/s]\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_36/2829474151.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# Process with multi-threading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting ASR evaluation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         results_df = process_from_template_df(\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Make sure this variable is defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mmodel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"base\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use smaller model for faster processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_36/2829474151.py\u001b[0m in \u001b[0;36mprocess_from_template_df\u001b[0;34m(df, model_size, device, frame_dur, hop_dur, pad, max_workers, audio_root_path, fallback_on_no_segments)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# Process file with ASR + WER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             df_segments = processor.process_file(\n\u001b[0m\u001b[1;32m    439\u001b[0m                 \u001b[0maudio_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sampling_rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_36/2829474151.py\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(self, audio_path, sr, vector, frame_dur, hop_dur, pad, reference_texts, show_progress, fallback_on_no_segments)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Processing segments from {os.path.basename(audio_path)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_to_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m                             len(pending), total_futures))\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Aj9sAjaxUu3g"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}