# Device-Directed Speech Segmentation: A New Paradigm Beyond Detection

<div align="center">

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-arXiv-b31b1b.svg)](PAPER_LINK)
[![Dataset](https://img.shields.io/badge/ğŸ—‚ï¸_Dataset-Kaggle-20beff.svg)](https://www.kaggle.com/datasets/dung8204/device-directed-television-dataset-dtd)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-171515.svg)](https://github.com/dungdt-infopstats/Device-Directed-Speech-Segmentation)
[![License](https://img.shields.io/badge/ğŸ“‹_License-MIT-green.svg)](https://github.com/dungdt-infopstats/Device-Directed-Speech-Segmentation/blob/main/LICENSE)

*A novel frame-level approach for isolating device-directed speech segments in virtual assistant applications*

</div>

---

## ğŸ¯ Overview

Device-directed Speech Segmentation (DDSS) presents a promising approach to virtual assistant speech processing by moving beyond traditional utterance-level classification to precise frame-level segmentation. This method shows potential to significantly improve downstream ASR performance by isolating only the device-directed portions of speech.

## âœ¨ Key Features

- ğŸ™ï¸ **Novel DDSS Framework** - Frame-level segmentation for precise device-directed speech isolation
- ğŸ”§ **Comprehensive Data Pipeline** - Reproducible synthesis pipeline for multiple VA domains
- ğŸ“Š **Public DTD Dataset** - First open dataset with 330+ hours of TV-domain commands
- ğŸ¤– **Multiple Model Variants** - Acoustic, ASR, and Fusion-based architectures

## ğŸš€ Setup

> **ğŸ“– Documentation Reference**  
> Complete setup instructions are maintained in the project's documentation directory.  
> **Link**: [Setup Documentation](https://github.com/dungdt-infopstats/Device-Directed-Speech-Segmentation/tree/main/docs)
## ğŸ“ Dataset

### ğŸ”— Access
<div align="center">

[![Kaggle Dataset](https://img.shields.io/badge/ğŸ“Š_DTD_Dataset-Kaggle-20beff?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/datasets/dung8204/device-directed-television-dataset-dtd)

</div>

### ğŸ“‹ Dataset Information
| **Property** | **Details** |
|--------------|-------------|
| ğŸ“ **Size** | 330+ hours of TV-domain commands |
| ğŸ”„ **Split** | 80/20 train/test, no speaker overlap |
| ğŸ­ **Scenarios** | 5 types: non-command, single-command, chain-command, single-mix, chain-mix |
| ğŸ“ **Format** | WAV files + JSON annotations |
| ğŸŒ **Domain** | Television commands (channels, movies, apps) |

### ğŸµ Sample Audio Examples

<details>
<summary>Click to see scenario examples</summary>

**Single-command:**
> "Turn on YouTube"

**Chain-command:** 
> "Open Netflix, search for action movies, play the first result"

**Single-mix:**
> "Turn on YouTube" (to device) + "What do you want to watch?" (to another person)

**Chain-mix:**
> "Open the weather app" + conversational speech + "Set volume to 50%"

</details>

## ğŸ† Results

| **Method** | **WER â†“** | **D â†“** | **I â†“** | **S â†“** | **D+S â†“** |
|------------|-----------|---------|---------|---------|-----------|
| No-filtering | 271.6% | 2.5% | 252.5% | 16.6% | 19.1% |
| Detection-only | 203.9% | 2.5% | 184.8% | 16.6% | 19.1% |
| **ğŸ¥‡ Fusion DDSS** | **47.8%** | **5.7%** | **29.5%** | **12.6%** | **18.3%** |
| Oracle DDSS | 22.4% | 3.5% | 8.4% | 10.5% | 14.0% |

## ğŸ“š Citation


## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Contact

- **Tri Dung Do** - dungdt.research@gmail.com
---
<div align="center">
<i>Research conducted during internship at Voice Team - Viettel AI â¤ï¸</i>
</div>
