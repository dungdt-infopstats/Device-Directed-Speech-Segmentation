{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dungdt-infopstats/TV-command-synthesis/blob/main/src_prototype/Phase2_VCTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F5-TTS\n",
        "!pip install -q f5-tts"
      ],
      "metadata": {
        "id": "oYB69oHn6KrE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference Speech\n",
        "!gdown 1G5APBDW_BlWAyXW_76RO24-wK6XqWkNe --quiet\n",
        "# Reference Meta (including Text)\n",
        "!gdown 1eJ7migpI5HXW_ZsAdUnY2S7WL-cwLG6e --quiet"
      ],
      "metadata": {
        "id": "BZbnEWUL9fUD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q vctk_ref_audio.zip\n",
        "!unzip -q vctk_ref_json.zip"
      ],
      "metadata": {
        "trusted": true,
        "id": "qlw9yv7gO0G2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm\n",
        "\n",
        "def add_silence_to_wav(input_dir, output_dir, silence_duration_ms=1000):\n",
        "    # Tạo thư mục output nếu chưa tồn tại\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Lấy danh sách file .wav\n",
        "    wav_files = [f for f in os.listdir(input_dir) if f.lower().endswith(\".wav\")]\n",
        "\n",
        "    # Loop qua danh sách file với tqdm\n",
        "    for filename in tqdm(wav_files, desc=\"Processing WAV files\"):\n",
        "        filepath = os.path.join(input_dir, filename)\n",
        "\n",
        "        # Load audio\n",
        "        audio = AudioSegment.from_wav(filepath)\n",
        "\n",
        "        # Tạo đoạn silence\n",
        "        silence = AudioSegment.silent(duration=silence_duration_ms)\n",
        "\n",
        "        # Ghép audio + silence\n",
        "        padded_audio = audio + silence\n",
        "\n",
        "        # Lưu file mới\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        padded_audio.export(output_path, format=\"wav\")\n",
        "\n",
        "# Ví dụ chạy\n",
        "add_silence_to_wav(\"audio\", \"pad_audio\", silence_duration_ms=1000)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "TsMWnNhOO0G3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "\n",
        "def filter_audio_json(audio_dir, json_dir, output_audio_dir, output_json_dir, max_duration=12.0):\n",
        "    \"\"\"\n",
        "    Lọc bỏ các file audio có độ dài > max_duration và đồng bộ file JSON cùng tên.\n",
        "\n",
        "    Args:\n",
        "        audio_dir (str): Thư mục chứa audio input.\n",
        "        json_dir (str): Thư mục chứa json input.\n",
        "        output_audio_dir (str): Thư mục chứa audio output.\n",
        "        output_json_dir (str): Thư mục chứa json output.\n",
        "        max_duration (float): Ngưỡng thời lượng tối đa (giây).\n",
        "    \"\"\"\n",
        "    os.makedirs(output_audio_dir, exist_ok=True)\n",
        "    os.makedirs(output_json_dir, exist_ok=True)\n",
        "\n",
        "    for file in os.listdir(audio_dir):\n",
        "        if file.endswith((\".wav\", \".mp3\", \".flac\")):  # lọc định dạng audio\n",
        "            audio_path = os.path.join(audio_dir, file)\n",
        "            try:\n",
        "                y, sr = librosa.load(audio_path, sr=None)\n",
        "                duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "                if duration <= max_duration:\n",
        "                    # copy audio\n",
        "                    shutil.copy(audio_path, os.path.join(output_audio_dir, file))\n",
        "\n",
        "                    # copy json nếu tồn tại\n",
        "                    json_file = os.path.splitext(file)[0] + \".json\"\n",
        "                    json_path = os.path.join(json_dir, json_file)\n",
        "                    if os.path.exists(json_path):\n",
        "                        shutil.copy(json_path, os.path.join(output_json_dir, json_file))\n",
        "            except Exception as e:\n",
        "                print(f\"Lỗi khi đọc {file}: {e}\")\n",
        "\n",
        "    print(\"Hoàn thành lọc audio + json.\")\n"
      ],
      "metadata": {
        "id": "EJWtmukOvNzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_audio_json(\n",
        "    audio_dir=\"pad_audio\",\n",
        "    json_dir=\"json\",\n",
        "    output_audio_dir=\"filtered_audio\",\n",
        "    output_json_dir=\"filtered_json\",\n",
        "    max_duration=12.0\n",
        ")\n"
      ],
      "metadata": {
        "id": "ihcPmJBHvyVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Đường dẫn tới thư mục chứa audio\n",
        "audio_dir = \"/content/filtered_audio\"\n",
        "\n",
        "durations = []\n",
        "\n",
        "# Lặp qua các file audio trong thư mục\n",
        "for file in os.listdir(audio_dir):\n",
        "    if file.endswith((\".wav\", \".mp3\", \".flac\")):  # lọc định dạng audio\n",
        "        file_path = os.path.join(audio_dir, file)\n",
        "        try:\n",
        "            y, sr = librosa.load(file_path, sr=None)  # load với sampling rate gốc\n",
        "            duration = librosa.get_duration(y=y, sr=sr)\n",
        "            durations.append(duration)\n",
        "        except Exception as e:\n",
        "            print(f\"Không đọc được file {file}: {e}\")\n",
        "\n",
        "# Vẽ histogram phân bố độ dài\n",
        "plt.hist(durations, bins=30, edgecolor=\"black\")\n",
        "plt.xlabel(\"Thời lượng (giây)\")\n",
        "plt.ylabel(\"Số lượng file\")\n",
        "plt.title(\"Phân bố độ dài speech trong thư mục\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MM_SS4y_wF3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "import random\n",
        "import ast\n",
        "import numpy as np\n",
        "import uuid\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "import time\n",
        "from typing import Any, List\n",
        "from importlib.resources import files\n",
        "from f5_tts.api import F5TTS\n",
        "\n",
        "class ReferenceCache:\n",
        "    def __init__(self, audio_folder_path: str, json_folder_path: str):\n",
        "        self.audio_folder_path = Path(audio_folder_path)\n",
        "        self.json_folder_path = Path(json_folder_path)\n",
        "        self._audio_files = None\n",
        "        self._json_files = None\n",
        "        self._ref_texts = {}\n",
        "\n",
        "    @property\n",
        "    def audio_files(self):\n",
        "        if self._audio_files is None:\n",
        "            self._audio_files = [f for f in self.audio_folder_path.iterdir() if f.is_file()]\n",
        "        return self._audio_files\n",
        "\n",
        "    @property\n",
        "    def json_files(self):\n",
        "        if self._json_files is None:\n",
        "            self._json_files = [f for f in self.json_folder_path.iterdir() if f.suffix == '.json']\n",
        "        return self._json_files\n",
        "\n",
        "    def get_ref_text(self, json_path: Path) -> str:\n",
        "        if str(json_path) not in self._ref_texts:\n",
        "            with open(json_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                self._ref_texts[str(json_path)] = data.get('text', '')\n",
        "        return self._ref_texts[str(json_path)]\n",
        "\n",
        "    def sample_reference(self):\n",
        "        # audio_file = random.choice(self.audio_files)\n",
        "        json_file = random.choice(self.json_files)\n",
        "        ref_id = json_file.stem\n",
        "        audio_file = os.path.join(self.audio_folder_path, f\"{ref_id}.wav\")\n",
        "        ref_speech_path = str(audio_file)\n",
        "        ref_text = self.get_ref_text(json_file)\n",
        "        return ref_id, ref_speech_path, ref_text"
      ],
      "metadata": {
        "id": "PydQZuRQ_9A9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "import random\n",
        "import ast\n",
        "import numpy as np\n",
        "import uuid\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "import time\n",
        "from typing import Any, List\n",
        "from importlib.resources import files\n",
        "from f5_tts.api import F5TTS\n",
        "\n",
        "class SpeechSynthesis:\n",
        "  def __init__(self, ref_folder_path, json_folder_path, num_workers):\n",
        "    self.ref_folder_path = ref_folder_path\n",
        "    self.json_folder_path = json_folder_path\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "  def load_model(self):\n",
        "    f5tts = F5TTS(device = 'cuda')\n",
        "    return f5tts\n",
        "\n",
        "\n",
        "  def audio_generate(self, command: str, model, ref_file: str = \"\", ref_text: str = \"\"):\n",
        "      wav, sr, spec = model.infer(\n",
        "          ref_file=ref_file,\n",
        "          ref_text=ref_text,\n",
        "          gen_text=command,\n",
        "          seed=None,\n",
        "      )\n",
        "      return wav, sr, spec\n",
        "\n",
        "  def process_single_command(self, row: pd.Series, ref_cache: ReferenceCache, export_path: str, model: Any):\n",
        "    try:\n",
        "        ref_id, ref_speech_path, ref_text = ref_cache.sample_reference()\n",
        "        wav, sr, _ = self.audio_generate(row['text'], model, ref_speech_path, ref_text)\n",
        "\n",
        "        cur_id = row['id']\n",
        "        cmd_path = Path(export_path) / f\"{row['type']}_{cur_id}\"\n",
        "        cmd_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Save full audio\n",
        "        sf.write(cmd_path / f\"{row['type']}_{cur_id}_full.wav\", wav, sr)\n",
        "\n",
        "        type_segments = {}\n",
        "        text_segments = {}\n",
        "\n",
        "        if pd.notna(row['segments']) and row['segments'] not in [None, \"\", \"nan\"]:\n",
        "            seg_list = ast.literal_eval(row['segments'])\n",
        "            for count, seg in enumerate(seg_list):\n",
        "                key = list(seg.keys())[0]\n",
        "                seg_wav, seg_sr, _ = self.audio_generate(seg[key], model, ref_speech_path, ref_text)\n",
        "                sf.write(cmd_path / f\"{row['type']}_{cur_id}_seg_{count}.wav\", seg_wav, seg_sr)\n",
        "                list_key = list(seg.keys())\n",
        "                type_segments[list_key[0]] = seg[list_key[1]] if len(list_key) > 1 else \"\"\n",
        "                text_segments[list_key[0]] = seg[list_key[0]]\n",
        "\n",
        "        json_template = {\n",
        "            \"id\": cur_id,\n",
        "            \"type\": row['type'],\n",
        "            \"command\": row['text'],\n",
        "            \"sampling_rate\": sr,\n",
        "            \"num_segments\": len(type_segments),\n",
        "            \"type_segments\": type_segments,\n",
        "            \"text_segments\": text_segments,\n",
        "            \"ref_id\": ref_id,\n",
        "            \"ref_file\": ref_speech_path,\n",
        "            \"ref_text\": ref_text\n",
        "        }\n",
        "        with open(cmd_path / f\"{row['type']}_{cur_id}.json\", 'w', encoding='utf-8') as f:\n",
        "            json.dump(json_template, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        return json_template\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process: {row['text']}, error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "  def worker_task(self, rows: List[pd.Series], ref_folder: str, json_folder: str, export_path: str):\n",
        "      # Mỗi worker load model riêng\n",
        "      model = self.load_model()\n",
        "      ref_cache = ReferenceCache(ref_folder, json_folder)\n",
        "      results = []\n",
        "      for row in rows:\n",
        "          res = self.process_single_command(row, ref_cache, export_path, model)\n",
        "          if res:\n",
        "              results.append(res)\n",
        "      return results\n",
        "\n",
        "  def command_synthesis_pipeline_multi_model(\n",
        "    self,\n",
        "    text_command,\n",
        "    export_path\n",
        "  ):\n",
        "    start_time = time.time()\n",
        "    os.makedirs(export_path, exist_ok=True)\n",
        "\n",
        "    if self.num_workers is None:\n",
        "        self.num_workers = min(mp.cpu_count(), 4)  # Giới hạn số model load\n",
        "\n",
        "    # Chia dữ liệu thành N phần, mỗi worker xử lý riêng\n",
        "    chunks = np.array_split(text_command, self.num_workers)\n",
        "\n",
        "    all_results = []\n",
        "    with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
        "        futures = [\n",
        "            executor.submit(self.worker_task, chunk.to_dict('records'), self.ref_folder_path, self.json_folder_path, export_path)\n",
        "            for chunk in chunks\n",
        "        ]\n",
        "        for i, future in enumerate(futures):\n",
        "            res_list = future.result()\n",
        "            all_results.extend(res_list)\n",
        "            print(f\"Worker {i+1} done ({len(res_list)} items)\")\n",
        "\n",
        "    print(f\"Pipeline finished in {time.time() - start_time:.2f}s\")\n",
        "    return pd.DataFrame(all_results)\n",
        "\n"
      ],
      "metadata": {
        "id": "sLGEgwVFtfTJ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "gid = '1UVlc-elJEGK6xvGct4QorySYjn2ISt7W'\n",
        "url = f\"https://drive.google.com/uc?id={gid}\"\n",
        "\n",
        "output = gdown.download(url, quiet=False)  # output sẽ là tên file đã tải"
      ],
      "metadata": {
        "id": "HVzIdoMcBWZ_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q {output}"
      ],
      "metadata": {
        "id": "HcNX13tSBi1K",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "param = {\n",
        "    'ref_folder_path': \"filtered_audio\",\n",
        "    'json_folder_path': \"filtered_json\",\n",
        "    'num_workers': 4,\n",
        "}\n",
        "\n",
        "csv_folder = f'{os.path.splitext(output)[0]}'\n",
        "export_folder = 'synthesis_command_pad'\n",
        "\n",
        "def main(export_folder):\n",
        "  os.makedirs(export_folder, exist_ok=True)\n",
        "  list_speech_df = []\n",
        "  speech_synthesis = SpeechSynthesis(**param)\n",
        "  for csv_file in os.listdir(csv_folder):\n",
        "    if csv_file.endswith('.csv'):\n",
        "      csv_path = os.path.join(csv_folder, csv_file)\n",
        "      df = pd.read_csv(csv_path)\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "    name = os.path.splitext(csv_file)[0]\n",
        "    export_path = f'{export_folder}/synthesis_command_{name}'\n",
        "    os.makedirs(export_path, exist_ok=True)\n",
        "    df_res = speech_synthesis.command_synthesis_pipeline_multi_model(df, export_path=export_path)\n",
        "    shutil.make_archive(export_path, 'zip', export_path)\n",
        "    list_speech_df.append(df_res)\n",
        "\n",
        "    df_path = os.path.join(export_path, f'synthesis_command_{name}.csv')\n",
        "    df.to_csv(df_path, index=False)\n",
        "\n",
        "  list_speech_df = pd.concat(list_speech_df)\n",
        "  list_speech_df.to_csv('synthesis_command.csv', index=False)"
      ],
      "metadata": {
        "id": "LDCJAXX16TJB",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  main(export_folder = export_folder)"
      ],
      "metadata": {
        "id": "4MhRnbPfAEEm",
        "trusted": true,
        "execution": {
          "execution_failed": "2025-08-20T16:04:30.503Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!zip synthesis_command.zip /content/synthesis_command_pad -r"
      ],
      "metadata": {
        "id": "rRwMH8O5CXc-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QibdcBwVOxLR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}