{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Phase3_ForceAlighment",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10udCryp7/TV-command-synthesis/blob/main/src_prototype/Phase3_ForceAlighment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1MrkteyPMIhLgki82_qJ_A9JDOIme3za3\n",
        "!unzip -q 100-samples.zip"
      ],
      "metadata": {
        "trusted": true,
        "id": "P0HVDU6LRRJA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 121dcbCvDVzB22uelCeYkg4Fs8TVbQ1tp"
      ],
      "metadata": {
        "trusted": true,
        "id": "4mA75G_vRRJB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"100-samples.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-18T03:31:16.858158Z",
          "iopub.execute_input": "2025-08-18T03:31:16.858441Z",
          "iopub.status.idle": "2025-08-18T03:31:17.193368Z",
          "shell.execute_reply.started": "2025-08-18T03:31:16.85842Z",
          "shell.execute_reply": "2025-08-18T03:31:17.192823Z"
        },
        "id": "f10yui0MRRJB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U openai-whisper"
      ],
      "metadata": {
        "trusted": true,
        "id": "hdYH7dQfRRJB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import itertools\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class SpeechCleaning:\n",
        "    def __init__(self, cant_clean_list = None):\n",
        "        self.model = whisper.load_model(\"medium\")\n",
        "        if not cant_clean_list:\n",
        "            self.cant_clean_list = []\n",
        "        else:\n",
        "            self.cant_clean_list = cant_clean_list\n",
        "    def clean_pipeline(self, export_dir: str, data: pd.DataFrame, speech_folder: str, padding = None):\n",
        "        os.makedirs(export_dir, exist_ok = True)\n",
        "        for idx, row in data.iterrows():\n",
        "\n",
        "            file_name = f\"{row['type']}_{row['id']}\"\n",
        "            file_type = \"full\"\n",
        "\n",
        "            start, end = self.get_clean_range(file_name = file_name, file_type = file_type, padding = padding, speech_folder = speech_folder)\n",
        "            trimmed_audio = self.trim_audio(file_name = file_name, file_type = file_type,\n",
        "                                                      start = start, end = end, speech_folder = speech_folder)\n",
        "\n",
        "            os.makedirs(os.path.join(export_dir, file_name), exist_ok = True)\n",
        "            out_path = os.path.join(export_dir, file_name, f\"{file_name}_{file_type}_trimmed.wav\")\n",
        "            trimmed_audio.export(out_path, format=\"wav\")\n",
        "\n",
        "            if row['type'] in ['single_mix', 'chain_mix']:\n",
        "\n",
        "               for i in range(row['num_segments']):\n",
        "                   file_type = f\"seg_{i}\"\n",
        "                   start, end = self.get_clean_range(file_name = file_name, file_type = file_type, padding = padding, speech_folder = speech_folder)\n",
        "                   trimmed_audio = self.trim_audio(file_name = file_name, file_type = file_type,\n",
        "                                                              start = start, end = end, speech_folder = speech_folder)\n",
        "\n",
        "                   os.makedirs(os.path.join(export_dir, file_name), exist_ok = True)\n",
        "                   out_path = os.path.join(export_dir, file_name, f\"{file_name}_{file_type}_trimmed.wav\")\n",
        "                   trimmed_audio.export(out_path, format=\"wav\")\n",
        "\n",
        "\n",
        "    def get_clean_range(self, file_name: str, file_type: str, speech_folder: str, padding = None):\n",
        "        # prepare whisper words\n",
        "        file_path = os.path.join(speech_folder, file_name, f\"{file_name}_{file_type}.wav\")\n",
        "\n",
        "        transcribe = self.model.transcribe(file_path, word_timestamps=True)\n",
        "        try:\n",
        "            whisper_words = [speaker['words'] for speaker in transcribe['segments']]\n",
        "\n",
        "            whisper_words = list(itertools.chain.from_iterable(whisper_words))\n",
        "        except Exception as e:\n",
        "            print(file_name + \" \" + file_type + \" \" + 'cant transcribe')\n",
        "            self.cant_clean_list.append((file_name, file_type, \"cant transcribe\"))\n",
        "            return None, None\n",
        "\n",
        "        # prepare reference text\n",
        "        meta_path = os.path.join(speech_folder, file_name, f\"{file_name}.json\")\n",
        "\n",
        "        with open(meta_path, \"r\", encoding = \"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if file_type == \"full\":\n",
        "            ref_text = data['command']\n",
        "        else:\n",
        "            num_seg = file_type.split(\"_\")[1]\n",
        "            ref_text = data['text_segments'][num_seg]\n",
        "\n",
        "        try:\n",
        "            start, end = self.get_start_end_from_alignment(ref_text = ref_text,\n",
        "                                                  whisper_words = whisper_words)\n",
        "            if padding:\n",
        "                start = max(0, start - padding)\n",
        "                end = end + padding\n",
        "        except Exception as e:\n",
        "            # Problems with long synthesis, should use only with segment\n",
        "            print(file_name + \" \" + file_type + \" \" + 'cant get start end')\n",
        "            print(e)\n",
        "            print(f'ref_text: {ref_text}')\n",
        "            print(f'whisper_words: {whisper_words}')\n",
        "            self.cant_clean_list.append((file_name, file_type, \"cant get start end\"))\n",
        "            return None, None\n",
        "        return start, end\n",
        "\n",
        "    def trim_audio(self, file_name, file_type, start, end, speech_folder):\n",
        "        file_path = os.path.join(speech_folder, file_name, f\"{file_name}_{file_type}.wav\")\n",
        "\n",
        "        audio = AudioSegment.from_wav(file_path)\n",
        "        if start and end:\n",
        "\n",
        "            trimmed_audio = audio[start*1000 : end*1000]\n",
        "            return trimmed_audio\n",
        "        else:\n",
        "            return audio\n",
        "\n",
        "    def get_start_end_from_alignment(self, ref_text, whisper_words):\n",
        "        ref_words = self.normalize_text(ref_text).split()\n",
        "        hypo_words = [self.normalize_text(w['word']) for w in whisper_words]\n",
        "\n",
        "        start_idx, end_idx = self.smith_waterman_fuzzy(ref_words, hypo_words)\n",
        "        start_time = whisper_words[start_idx]['start']\n",
        "        end_time = whisper_words[end_idx]['end']\n",
        "\n",
        "        return start_time, end_time\n",
        "\n",
        "    def smith_waterman_fuzzy(self, ref_words, hypo_words, match_score=2, fuzzy_score=1, mismatch=-1, gap=-2):\n",
        "        m, n = len(ref_words), len(hypo_words)\n",
        "        score = np.zeros((m+1, n+1))\n",
        "        max_score = 0\n",
        "        max_pos = None\n",
        "\n",
        "        for i in range(1, m+1):\n",
        "            for j in range(1, n+1):\n",
        "                sim = self.word_similarity(ref_words[i-1], hypo_words[j-1])\n",
        "                if sim == 1:\n",
        "                    s = match_score\n",
        "                elif sim >= 0.8:\n",
        "                    s = fuzzy_score\n",
        "                else:\n",
        "                    s = mismatch\n",
        "\n",
        "                diag = score[i-1, j-1] + s\n",
        "                delete = score[i-1, j] + gap\n",
        "                insert = score[i, j-1] + gap\n",
        "                score[i, j] = max(0, diag, delete, insert)\n",
        "\n",
        "                if score[i, j] > max_score:\n",
        "                    max_score = score[i, j]\n",
        "                    max_pos = (i, j)\n",
        "\n",
        "        # Traceback\n",
        "        i, j = max_pos\n",
        "        end_j = j - 1\n",
        "        while i > 0 and j > 0 and score[i, j] > 0:\n",
        "            sim = self.word_similarity(ref_words[i-1], hypo_words[j-1])\n",
        "            if sim >= 0.8:\n",
        "                i -= 1\n",
        "                j -= 1\n",
        "            elif score[i-1, j] + gap == score[i, j]:\n",
        "                i -= 1\n",
        "            else:\n",
        "                j -= 1\n",
        "        start_j = j\n",
        "\n",
        "        return start_j, end_j\n",
        "\n",
        "    def str2list(self, list_str: str):\n",
        "        return ast.literal_eval(list_str)\n",
        "\n",
        "    def word_similarity(self, w1, w2):\n",
        "        return SequenceMatcher(None, w1, w2).ratio()\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        return re.sub(r'[^\\w\\s]', '', text.lower()).strip()\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-18T03:33:58.996199Z",
          "iopub.execute_input": "2025-08-18T03:33:58.996926Z",
          "iopub.status.idle": "2025-08-18T03:33:59.015516Z",
          "shell.execute_reply.started": "2025-08-18T03:33:58.996902Z",
          "shell.execute_reply": "2025-08-18T03:33:59.014793Z"
        },
        "id": "kErOBA-MRRJC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SpeechCleaning()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-18T03:34:00.240053Z",
          "iopub.execute_input": "2025-08-18T03:34:00.240376Z",
          "iopub.status.idle": "2025-08-18T03:34:13.696788Z",
          "shell.execute_reply.started": "2025-08-18T03:34:00.240353Z",
          "shell.execute_reply": "2025-08-18T03:34:13.696263Z"
        },
        "id": "N4NspnwARRJD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/working/100-samples.csv\", index_col = 0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-18T03:34:13.698657Z",
          "iopub.execute_input": "2025-08-18T03:34:13.698864Z",
          "iopub.status.idle": "2025-08-18T03:34:13.706273Z",
          "shell.execute_reply.started": "2025-08-18T03:34:13.698848Z",
          "shell.execute_reply": "2025-08-18T03:34:13.705489Z"
        },
        "id": "eEY97JShRRJE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sc.clean_pipeline(export_dir = 'trimmed_speech', speech_folder = '/kaggle/working/synthesis_command', data = df, padding = 0.3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-18T03:34:13.707171Z",
          "iopub.execute_input": "2025-08-18T03:34:13.707448Z",
          "iopub.status.idle": "2025-08-18T03:41:20.378974Z",
          "shell.execute_reply.started": "2025-08-18T03:34:13.707422Z",
          "shell.execute_reply": "2025-08-18T03:41:20.378139Z"
        },
        "id": "JQxg7gWrRRJF",
        "outputId": "7561936e-fa87-434b-a6c5-e6be9c390228"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "single_active_4ff7f40d full cant get start end\ncannot unpack non-iterable NoneType object\nref_text: show me Cartoon Network\nwhisper_words: [{'word': ' What', 'start': 0.44000000000000006, 'end': 0.88, 'probability': 0.2911490797996521}, {'word': ' a', 'start': 0.88, 'end': 1.08, 'probability': 0.19421282410621643}, {'word': ' pleasant', 'start': 1.08, 'end': 1.3, 'probability': 0.23018227517604828}, {'word': ' tome,', 'start': 1.3, 'end': 1.7, 'probability': 0.5129103735089302}, {'word': \" you're\", 'start': 1.76, 'end': 1.94, 'probability': 0.4445706903934479}, {'word': ' a', 'start': 1.94, 'end': 2.0, 'probability': 0.19106259942054749}, {'word': ' first', 'start': 2.0, 'end': 2.26, 'probability': 0.5872543454170227}, {'word': '-gen', 'start': 2.26, 'end': 2.72, 'probability': 0.4452144652605057}, {'word': ' dab,', 'start': 2.72, 'end': 3.14, 'probability': 0.5577821135520935}, {'word': ' and', 'start': 3.46, 'end': 3.64, 'probability': 0.920242965221405}, {'word': ' here', 'start': 3.64, 'end': 3.8, 'probability': 0.814730703830719}, {'word': ' that', 'start': 3.8, 'end': 4.0, 'probability': 0.8039153814315796}, {'word': ' day', 'start': 4.0, 'end': 4.24, 'probability': 0.909503698348999}, {'word': ' is', 'start': 4.24, 'end': 4.4, 'probability': 0.6538426280021667}, {'word': ' uberbeck', 'start': 4.4, 'end': 4.92, 'probability': 0.5682819336652756}, {'word': ' frady.', 'start': 4.92, 'end': 5.16, 'probability': 0.5877803415060043}]\nsingle_mix_d337321c seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: Can you\nwhisper_words: []\nchain_mix_79b56df5 full cant get start end\ncannot unpack non-iterable NoneType object\nref_text: set volume to 10, do you remember my birthday is next week? switch to channel Cartoon Network.\nwhisper_words: []\nsingle_mix_5143fc18 seg_1 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: while\nwhisper_words: [{'word': ' Amazingly', 'start': 0.0, 'end': 0.0, 'probability': 0.005326938109647017}, {'word': ' cool.', 'start': 0.0, 'end': 1.14, 'probability': 0.006055118050426245}, {'word': ' Yes', 'start': 1.16, 'end': 1.56, 'probability': 0.004368339199572802}, {'word': ' sir,', 'start': 1.56, 'end': 2.1, 'probability': 0.003025027457624674}, {'word': ' The', 'start': 2.12, 'end': 3.2, 'probability': 0.0013099685311317444}, {'word': ' you', 'start': 3.18, 'end': 3.2, 'probability': 0.07016493380069733}]\nsingle_mix_5143fc18 seg_3 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: you\nwhisper_words: [{'word': ' JSONU', 'start': 0.0, 'end': 1.9, 'probability': 0.2021235004067421}]\nsingle_mix_5143fc18 seg_5 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: she\nwhisper_words: [{'word': ' Jazshii', 'start': 0.0, 'end': 1.9, 'probability': 0.12103683159997065}]\nsingle_mix_5143fc18 seg_9 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: at\nwhisper_words: []\nsingle_mix_5143fc18 seg_10 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: the\nwhisper_words: [{'word': ' JSON', 'start': 0.0, 'end': 1.78, 'probability': 0.529983639717102}]\nsingle_mix_966300b9 seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: set volume to 10\nwhisper_words: [{'word': ' Jason', 'start': 0.56, 'end': 1.26, 'probability': 0.2885092496871948}, {'word': ' You', 'start': 1.26, 'end': 1.5, 'probability': 0.0038972662296146154}]\nsingle_active_7aa90624 full cant get start end\ncannot unpack non-iterable NoneType object\nref_text: turn off subtitles\nwhisper_words: [{'word': ' Adorno,', 'start': 0.5599999999999998, 'end': 0.96, 'probability': 0.4713745787739754}, {'word': ' subtype.', 'start': 1.1, 'end': 1.36, 'probability': 0.5043217614293098}]\nsingle_mix_c6252315 seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: What\nwhisper_words: [{'word': ' Jason?', 'start': 0.0, 'end': 1.1, 'probability': 0.7641662359237671}]\nsingle_mix_c6252315 seg_1 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: do\nwhisper_words: [{'word': ' Jason', 'start': 0.0, 'end': 0.54, 'probability': 0.04797322303056717}]\nsingle_mix_c6252315 seg_2 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: you\nwhisper_words: [{'word': \" She's\", 'start': 0.0, 'end': 1.0, 'probability': 0.5927341431379318}, {'word': ' on.', 'start': 1.0, 'end': 1.0, 'probability': 0.4240727126598358}]\nsingle_mix_c6252315 seg_3 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: think\nwhisper_words: [{'word': \" I'm\", 'start': 0.0, 'end': 0.8, 'probability': 0.28169900365173817}, {'word': ' true', 'start': 0.8, 'end': 1.2, 'probability': 0.00026478510699234903}, {'word': ' Jen', 'start': 1.2, 'end': 1.64, 'probability': 0.05564477667212486}]\nsingle_mix_c6252315 seg_4 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: about\nwhisper_words: [{'word': ' This', 'start': 0.0, 'end': 0.98, 'probability': 0.5200225114822388}, {'word': ' one?', 'start': 0.98, 'end': 1.2, 'probability': 0.9363523125648499}, {'word': ' VOTE!', 'start': 1.58, 'end': 1.7, 'probability': 0.6384379267692566}]\nsingle_mix_c6252315 seg_5 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: that\nwhisper_words: [{'word': ' Jessen', 'start': 0.0, 'end': 1.36, 'probability': 0.5439496785402298}]\nsingle_mix_c6252315 seg_7 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: Set\nwhisper_words: [{'word': \" That's\", 'start': 0.0, 'end': 0.9, 'probability': 0.5607360526919365}, {'word': ' them.', 'start': 0.9, 'end': 1.0, 'probability': 0.34214717149734497}]\nsingle_mix_c6252315 seg_8 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: brightness\nwhisper_words: [{'word': ' Jeff', 'start': 0.3799999999999999, 'end': 0.74, 'probability': 0.7997738718986511}, {'word': ' Rice?', 'start': 0.74, 'end': 0.92, 'probability': 0.11012589186429977}]\nsingle_mix_c6252315 seg_9 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: to\nwhisper_words: [{'word': ' Jason', 'start': 0.0, 'end': 0.6, 'probability': 0.2780616283416748}]\nsingle_mix_c6252315 seg_10 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: 70.\nwhisper_words: []\nchain_mix_0969edce seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: unmute the TV\nwhisper_words: [{'word': ' Jason?', 'start': 0.0, 'end': 0.84, 'probability': 0.7884073257446289}]\nchain_mix_460f79b4 seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: scroll down\nwhisper_words: [{'word': ' Just', 'start': 0.9199999999999997, 'end': 1.2, 'probability': 0.3735354542732239}, {'word': ' go', 'start': 1.2, 'end': 1.34, 'probability': 0.7086660861968994}, {'word': ' on.', 'start': 1.34, 'end': 1.38, 'probability': 0.931724488735199}]\nchain_mix_460f79b4 seg_1 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: skip intro\nwhisper_words: [{'word': '以上', 'start': 0.0, 'end': 0.98, 'probability': 0.289216548204422}]\nsingle_mix_79892fde seg_2 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: while\nwhisper_words: [{'word': ' JSON,', 'start': 0.74, 'end': 1.26, 'probability': 0.651055634021759}, {'word': ' wild.', 'start': 1.66, 'end': 1.78, 'probability': 0.6291753053665161}]\nchain_mix_b211eaf6 seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: Set the volume to minimum\nwhisper_words: [{'word': ' below', 'start': 0.33999999999999997, 'end': 0.66, 'probability': 0.0736817717552185}, {'word': ' is', 'start': 0.66, 'end': 0.78, 'probability': 0.264555424451828}, {'word': ' costumes,', 'start': 0.78, 'end': 0.92, 'probability': 3.267126885475591e-05}, {'word': ' Jason.', 'start': 1.24, 'end': 1.4, 'probability': 0.4045279920101166}]\nchain_mix_b211eaf6 seg_2 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: rewind that show\nwhisper_words: [{'word': ' Jason.', 'start': 0.0, 'end': 0.02, 'probability': 0.7733314037322998}]\nsingle_active_6dc69584 full cant get start end\ncannot unpack non-iterable NoneType object\nref_text: open Spotify\nwhisper_words: [{'word': ' Jason.', 'start': 0.0, 'end': 0.68, 'probability': 0.5289405584335327}]\nchain_mix_2465bf55 seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: show me Nickelodeon\nwhisper_words: [{'word': ' Jason.', 'start': 0.0, 'end': 1.06, 'probability': 0.7531425356864929}]\nsingle_active_c2a0338e full cant get start end\ncannot unpack non-iterable NoneType object\nref_text: close Spotify\nwhisper_words: [{'word': ' Jess,', 'start': 0.0, 'end': 0.92, 'probability': 0.056910011917352676}, {'word': \" I'm\", 'start': 1.0, 'end': 1.0, 'probability': 0.9068235158920288}]\nsingle_active_484e94d0 full cant get start end\ncannot unpack non-iterable NoneType object\nref_text: mute the TV\nwhisper_words: [{'word': ' Jen', 'start': 0.0, 'end': 0.74, 'probability': 0.26775455474853516}]\nchain_mix_974cfec8 seg_0 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: change input to Netflix\nwhisper_words: [{'word': \" You've\", 'start': 0.45999999999999996, 'end': 0.76, 'probability': 0.4204769432544708}, {'word': ' got', 'start': 0.76, 'end': 0.88, 'probability': 0.8438436388969421}, {'word': ' a', 'start': 0.88, 'end': 0.96, 'probability': 0.6837365031242371}, {'word': ' whole', 'start': 0.96, 'end': 1.1, 'probability': 0.12884150445461273}, {'word': ' different', 'start': 1.1, 'end': 1.3, 'probability': 0.07384108006954193}, {'word': ' chain', 'start': 1.3, 'end': 1.46, 'probability': 0.1608496606349945}]\nchain_mix_974cfec8 seg_2 cant get start end\ncannot unpack non-iterable NoneType object\nref_text: turn off subtitles\nwhisper_words: [{'word': ' Tell', 'start': 0.28, 'end': 0.52, 'probability': 0.4803788363933563}, {'word': ' me', 'start': 0.52, 'end': 0.66, 'probability': 0.9434592127799988}, {'word': ' when', 'start': 0.66, 'end': 0.7, 'probability': 0.26091980934143066}, {'word': \" I'm\", 'start': 0.7, 'end': 0.82, 'probability': 0.5700608789920807}, {'word': ' not', 'start': 0.82, 'end': 0.9, 'probability': 0.5968596935272217}, {'word': ' subscribed.', 'start': 0.9, 'end': 1.12, 'probability': 0.45113837718963623}]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sc.cant"
      ],
      "metadata": {
        "trusted": true,
        "id": "tt7yh3EBRRJG"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}