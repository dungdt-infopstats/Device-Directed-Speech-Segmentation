{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10udCryp7/TV-command-synthesis/blob/main/src_prototype/Phase3_Concat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_json_folders(root_dir: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Duyệt tất cả thư mục con trong root_dir,\n",
        "    mỗi thư mục chứa một file JSON, load vào DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    root_dir : str\n",
        "        Thư mục gốc chứa các thư mục con.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame chứa dữ liệu từ tất cả file JSON.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for subdir in os.listdir(root_dir):\n",
        "        subpath = os.path.join(root_dir, subdir)\n",
        "        if os.path.isdir(subpath):\n",
        "            # tìm file json trong subdir\n",
        "            for fname in os.listdir(subpath):\n",
        "                if fname.endswith(\".json\"):\n",
        "                    fpath = os.path.join(subpath, fname)\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        try:\n",
        "                            obj = json.load(f)\n",
        "                            data.append(obj)\n",
        "                        except Exception as e:\n",
        "                            print(f\"⚠️ Lỗi đọc {fpath}: {e}\")\n",
        "    return pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "3454TotjkK2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1--F60ZQLlD5EKJ32On6MB5CHXW6V6ncJ"
      ],
      "metadata": {
        "id": "uruhVdHQkNXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q sample-5000-speech-synthesis-zip.zip"
      ],
      "metadata": {
        "id": "kj8CWufGkQ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "df_dict = {}\n",
        "for path in os.listdir('sample-5000-speech-synthesis-zip'):\n",
        "    root_folder = os.path.join('sample-5000-speech-synthesis-zip', path)\n",
        "    df = load_json_folders(root_folder)\n",
        "    df_dict[path] = df\n",
        "\n",
        "# => we have"
      ],
      "metadata": {
        "id": "KRU3Pf_VkU1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1ktYfos4wHLUtE1iuC1Pc_wV2cEsSzytm"
      ],
      "metadata": {
        "id": "J_oJcp-2GvMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q sample-5000-trimmed-speech.zip"
      ],
      "metadata": {
        "id": "s-NvU2ldJ6B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1bqztSQKwtHABu4_JHFQcRPoxUzAZmEWh"
      ],
      "metadata": {
        "id": "lbodveCPKoyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_df = pd.read_csv('sample-5000-bad-list.csv')"
      ],
      "metadata": {
        "id": "SF2WNRpWK2JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_list = set(bad_df['id'].values)"
      ],
      "metadata": {
        "id": "A7Wk_hFiK5jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict['synthesis_command_part_1']"
      ],
      "metadata": {
        "id": "h-C2K9FNMRb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "import ast\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import ast\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "class AudioConcatenator:\n",
        "    def __init__(self, bad_list=None):\n",
        "        self.bad_list = set(bad_list) if bad_list else set()\n",
        "\n",
        "    def _parse_segments(self, type_segments):\n",
        "        if isinstance(type_segments, str):\n",
        "            return ast.literal_eval(type_segments)\n",
        "        if isinstance(type_segments, dict):\n",
        "            return type_segments\n",
        "        raise ValueError(\"Unknown type_segments format\")\n",
        "\n",
        "    def _concat_file(self, row, input_folder, output_folder):\n",
        "        file_name = f\"{row['type']}_{row['id']}\"\n",
        "        type_segments = self._parse_segments(row['type_segments'])\n",
        "\n",
        "        combined = AudioSegment.silent(duration=0)\n",
        "        annotations, current_time_ms = [], 0\n",
        "        num_segments = row['num_segments']\n",
        "\n",
        "        for i in range(num_segments):\n",
        "            seg_path = os.path.join(input_folder, file_name, f\"{file_name}_seg_{i}_trimmed.wav\")\n",
        "            if not os.path.exists(seg_path):\n",
        "                print(f\"Missing: {seg_path}\")\n",
        "                continue\n",
        "\n",
        "            segment = AudioSegment.from_wav(seg_path)\n",
        "            duration_ms = len(segment)\n",
        "\n",
        "            label = type_segments.get(str(i), \"unknown\")\n",
        "            annotations.append({\n",
        "                \"label\": label,\n",
        "                \"start\": current_time_ms / 1000.0,\n",
        "                \"end\": (current_time_ms + duration_ms) / 1000.0\n",
        "            })\n",
        "\n",
        "            combined += segment\n",
        "            current_time_ms += duration_ms\n",
        "\n",
        "        return self._save_outputs(file_name, combined, annotations, output_folder)\n",
        "\n",
        "    def _get_non_mix(self, row, input_folder, output_folder):\n",
        "        file_name = f\"{row['type']}_{row['id']}\"\n",
        "        file_path = os.path.join(input_folder, file_name, f\"{file_name}_trimmed.wav\")\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            file_name_full = f\"{row['type']}_{row['id']}_full\"\n",
        "            file_path = os.path.join(input_folder, file_name, f\"{file_name_full}_trimmed.wav\")\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Missing: {file_path}\")\n",
        "            return None\n",
        "        segment = AudioSegment.from_wav(file_path)\n",
        "        duration_ms = len(segment)\n",
        "\n",
        "        label = \"non_active\" if row[\"type\"] == \"non_active\" else \"active\"\n",
        "        annotations = [{\n",
        "            \"label\": label,\n",
        "            \"start\": 0,\n",
        "            \"end\": duration_ms / 1000.0\n",
        "        }]\n",
        "\n",
        "        return self._save_outputs(file_name, segment, annotations, output_folder)\n",
        "\n",
        "    def _save_outputs(self, file_name, audio, annotations, output_folder):\n",
        "        file_output_dir = os.path.join(output_folder, file_name)\n",
        "        os.makedirs(file_output_dir, exist_ok=True)\n",
        "\n",
        "        # Save audio\n",
        "        output_wav = os.path.join(file_output_dir, f\"{file_name}_concat.wav\")\n",
        "        audio.export(output_wav, format=\"wav\")\n",
        "\n",
        "        # Save annotations\n",
        "        output_json = os.path.join(file_output_dir, f\"{file_name}.json\")\n",
        "        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(annotations, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Saved: {output_wav}, {output_json}\")\n",
        "        return {\"wav\": output_wav, \"json\": output_json}\n",
        "\n",
        "    def process(self, metadata, input_folder, output_folder):\n",
        "        \"\"\"Xử lý toàn bộ metadata với input/output folder chỉ định\"\"\"\n",
        "        results = []\n",
        "        for _, row in metadata.iterrows():\n",
        "            file_name = f\"{row['type']}_{row['id']}\"\n",
        "            file_name_full = f\"{row['type']}_{row['id']}_full\"\n",
        "            if file_name in self.bad_list or file_name_full in self.bad_list:\n",
        "                print(f\"Skip {file_name}\")\n",
        "                continue\n",
        "\n",
        "            if row[\"num_segments\"] != 0:\n",
        "                result = self._concat_file(row, input_folder, output_folder)\n",
        "            else:\n",
        "                result = self._get_non_mix(row, input_folder, output_folder)\n",
        "\n",
        "            if result:\n",
        "                results.append(result)\n",
        "\n",
        "        return results\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T08:58:31.352844Z",
          "iopub.execute_input": "2025-08-14T08:58:31.353273Z",
          "iopub.status.idle": "2025-08-14T08:58:31.365833Z",
          "shell.execute_reply.started": "2025-08-14T08:58:31.353243Z",
          "shell.execute_reply": "2025-08-14T08:58:31.364662Z"
        },
        "id": "ulqeRucuhedz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "concat_tool = AudioConcatenator(bad_list=bad_list)\n",
        "input_root = \"trimmed_speech\"\n",
        "\n",
        "\n",
        "results_dict = {}\n",
        "for folder, df in tqdm(df_dict.items(), desc=\"Processing folders\", unit=\"folder\"):\n",
        "    name = Path(folder).name\n",
        "    output_folder = os.path.join(\"concat_speech\", name)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    input_folder = os.path.join(input_root, name)\n",
        "    results = concat_tool.process(df, input_folder=input_folder, output_folder=output_folder)\n",
        "    results_dict[name] = results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T08:58:33.331632Z",
          "iopub.execute_input": "2025-08-14T08:58:33.332789Z",
          "iopub.status.idle": "2025-08-14T08:58:33.392245Z",
          "shell.execute_reply.started": "2025-08-14T08:58:33.332754Z",
          "shell.execute_reply": "2025-08-14T08:58:33.391148Z"
        },
        "id": "q3c2C3jxhed0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!zip sample-5000-concat.zip concat_speech -r"
      ],
      "metadata": {
        "id": "Cn3qD-X-bNgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mutagen import File\n",
        "\n",
        "def total_audio_duration_hours(folder_path: str) -> float:\n",
        "    \"\"\"\n",
        "    Tính tổng thời lượng (giờ) của toàn bộ file âm thanh trong folder (bao gồm thư mục con).\n",
        "    Dùng mutagen để đọc metadata (nhanh hơn nhiều so với decode audio).\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): đường dẫn đến thư mục\n",
        "\n",
        "    Returns:\n",
        "        float: tổng số giờ của tất cả file âm thanh\n",
        "    \"\"\"\n",
        "    total_seconds = 0.0\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                audio = File(file_path)\n",
        "                if audio is not None and audio.info is not None:\n",
        "                    total_seconds += audio.info.length\n",
        "            except Exception:\n",
        "                # bỏ qua file không đọc được\n",
        "                continue\n",
        "\n",
        "    return total_seconds / 3600.0\n",
        "\n",
        "\n",
        "# ví dụ dùng\n",
        "if __name__ == \"__main__\":\n",
        "    folder = \"concat_speech\"\n",
        "    hours = total_audio_duration_hours(folder)\n",
        "    print(hours)\n"
      ],
      "metadata": {
        "id": "YUFNsf0JbUe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mutagen"
      ],
      "metadata": {
        "id": "vjmf5UYzdmin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e01lpew-evPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}