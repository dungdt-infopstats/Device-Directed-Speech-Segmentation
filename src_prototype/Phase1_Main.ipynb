{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7LBcYigaz+gkMIbf51QeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10udCryp7/TV-command-synthesis/blob/main/src_prototype/Phase1_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config of data_preparation\n",
        "\n",
        "content_list = [\n",
        "      ('app', '1NIPjwYGi5b1xuB_e8y1ks_oGZ_obalny'),\n",
        "      ('movie', '19xDdO_BZmpZLHlbXN-aNuEFU_xvqzFjn'),\n",
        "      ('song', '1-_bVYQUV8DJ4KvG5j7cK0ZcvJY6s9dre'),\n",
        "      ('tv', '1lZcb1cKaYwCS9wqHf8PXct-cpxAvM2Oz')\n",
        "]\n",
        "command_source = '1zHhi08gxGqc_qGTxoQH-YIP7vuzmu7v3'"
      ],
      "metadata": {
        "id": "7AC8CUXUFdkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "non_active_prompt = \"\"\"\n",
        "You are to generate {generated_nums} sentences of type \"non_active\".\n",
        "\n",
        "**Definition of \"non_active\":**\n",
        "- Sentences represent natural, everyday indoor human conversation.\n",
        "- Absolutely no TV/device commands.\n",
        "- Mentioning or talking about a command is still considered non_active — only direct device instructions count as active.\n",
        "\n",
        "**Input content:**\n",
        "- Use the following content list (after removing prefixes): {content_list}\n",
        "\n",
        "**Rules:**\n",
        "1. Use only human-to-human conversation, not device commands.\n",
        "2. Even if the sentence contains TV-related words, if it is not a direct command to the device, it is still non_active.\n",
        "3. Sentences must sound natural and conversational.\n",
        "4. Use the specific content ideas from the list.\n",
        "\n",
        "**Output format (JSON only):**\n",
        "```json\n",
        "{{\n",
        "  \"non_active\": [\n",
        "    {{ \"text\": \"...\",\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "single_active_prompt = \"\"\"\n",
        "You are to generate {generated_nums} sentences of type \"single_active\".\n",
        "\n",
        "**Definition of \"single_active\":**\n",
        "- Each sentence is a direct, clear TV/device command.\n",
        "- No human conversation or extra wording beyond the command.\n",
        "- The command must be something that could be spoken to a device to perform an action immediately.\n",
        "\n",
        "**Input:**\n",
        "- TV commands list: {command_list}\n",
        "- Content list (prefix removed): {content_list}\n",
        "\n",
        "**Rules:**\n",
        "1. Each sentence = exactly one direct TV/device command from the TV commands list.\n",
        "2. Do not use questions, hypotheticals, or descriptions — only imperative commands.\n",
        "3. No unrelated conversation or comments.\n",
        "4. Must sound natural as a spoken device instruction.\n",
        "\n",
        "**Output format (JSON only):**\n",
        "```json\n",
        "{{\n",
        "  \"single_active\": [\n",
        "    {{ \"text\": \"...\",\n",
        "  ]\n",
        "}}\n",
        "\n",
        "\"\"\"\n",
        "single_mix_prompt = \"\"\"\n",
        "You are to generate {generated_nums} sentences of type \"single_mix\".\n",
        "\n",
        "**Definition of \"single_mix\":**\n",
        "- Each sentence must contain exactly ONE direct, clear TV/device command + one unrelated human conversation.\n",
        "- The command must be an imperative statement addressed to the device, not a question or discussion.\n",
        "- The two parts must be completely unrelated.\n",
        "\n",
        "**Position requirement:**\n",
        "- In this task, the TV/device command should appear {command_position} in the sentence.\n",
        "\n",
        "**Input:**\n",
        "- TV commands list: {command_list}\n",
        "- Content list (prefix removed): {content_list}\n",
        "\n",
        "**Rules:**\n",
        "1. Exactly one direct TV/device command + one unrelated human conversation.\n",
        "2. The command must be in imperative form (telling the device to do something immediately).\n",
        "3. No hypotheticals, descriptions, or indirect mentions of commands.\n",
        "4. Commands and conversation must follow the specified position rule above.\n",
        "5. Sentences must sound natural.\n",
        "6. When splitting into segments, include every single word from the original sentence — no removals.\n",
        "\n",
        "**Output format (JSON only):**\n",
        "```json\n",
        "{{\n",
        "  \"single_mix\": [\n",
        "    {{\n",
        "      \"text\": \"...\",\n",
        "      \"segments\": [\n",
        "        {{ \"0\": \"...\", \"type\": \"active\" }},\n",
        "        {{ \"1\": \"...\", \"type\": \"non_active\" }}\n",
        "        // More segments if needed, but all words from the original sentence must be included\n",
        "      ]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "chain_active_prompt = \"\"\"\n",
        "You are to generate {generated_nums} sentences of type \"chain_active\".\n",
        "\n",
        "**Definition of \"chain_active\":**\n",
        "- Sentences contain multiple direct TV/device commands only.\n",
        "- All commands must be imperative instructions to the device.\n",
        "\n",
        "**Input:**\n",
        "- TV commands list: {command_list}\n",
        "- Content list (prefix removed): {content_list}\n",
        "\n",
        "**Rules:**\n",
        "1. Each sentence must have two or more imperative device commands from the provided list.\n",
        "2. No human conversation, questions, or descriptive phrases.\n",
        "3. Commands can be related or unrelated, but all must be valid direct instructions.\n",
        "4. Sentences should sound natural as a spoken command sequence.\n",
        "\n",
        "**Output format (JSON only):**\n",
        "```json\n",
        "{{\n",
        "  \"chain_active\": [\n",
        "    {{\n",
        "      \"text\": \"...\",\n",
        "  }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "chain_mix_prompt = \"\"\"\n",
        "You are to generate {generated_nums} sentences of type \"chain_mix\".\n",
        "\n",
        "**Definition of \"chain_mix\":**\n",
        "- Sentences must contain multiple direct TV/device commands + at least one unrelated human conversation.\n",
        "- Commands must be imperative instructions to the device, not questions or descriptions.\n",
        "\n",
        "**Position requirement:**\n",
        "- In this task, the sequence of TV/device commands should appear {command_position} in the sentence.\n",
        "\n",
        "**Input:**\n",
        "- TV commands list: {command_list}\n",
        "- Content list (prefix removed): {content_list}\n",
        "\n",
        "**Rules:**\n",
        "1. Each sentence must contain 2 or more direct imperative commands from the TV commands list.\n",
        "2. Must also contain at least one unrelated human conversation segment.\n",
        "3. Commands and conversation must follow the specified position rule above.\n",
        "4. No hypotheticals, indirect mentions, or descriptions — only direct instructions are active.\n",
        "5. Sentences must sound natural.\n",
        "6. Segments must cover the entire sentence with no missing words or characters.\n",
        "7. In segments, `\"type\"` must be `\"active\"` for commands and `\"non_active\"` for conversation.\n",
        "\n",
        "**Output format (JSON only):**\n",
        "```json\n",
        "{{\n",
        "  \"chain_mix\": [\n",
        "    {{\n",
        "      \"text\": \"...\",\n",
        "      \"segments\": [\n",
        "        {{ \"0\": \"...\", \"type\": \"active\" }},\n",
        "        {{ \"1\": \"...\", \"type\": \"non_active\" }}\n",
        "        // More segments as needed, but must cover 100% of the sentence\n",
        "      ]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "PROMPT_CORPUS = {\n",
        "    \"non_active\": non_active_prompt,\n",
        "    \"single_active\": single_active_prompt,\n",
        "    \"single_mix\": single_mix_prompt,\n",
        "    \"chain_active\": chain_active_prompt,\n",
        "    \"chain_mix\": chain_mix_prompt\n",
        "}\n",
        "\n",
        "list_position = [\n",
        "  \"at the beginning\",\n",
        "  \"at the end\",\n",
        "  \"in the middle\",\n",
        "  \"scattered throughout\",\n",
        "  \"before the conversation part\",\n",
        "  \"after the conversation part\",\n",
        "  \"surrounding the conversation part\",\n",
        "  \"split before and after the conversation part\",\n",
        "  \"alternating with conversation parts\",\n",
        "  \"mixed randomly with conversation parts\"\n",
        "]"
      ],
      "metadata": {
        "id": "NrhrN9DSH-tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_preparation.py\n",
        "'''\n",
        "for loading data\n",
        "\n",
        "design kiểu này bị cái phải chuẩn format và phải tự chuẩn bị data,\n",
        "cơ mà scale lên tính sau, miễn fix output là list string là được.\n",
        "\n",
        "'''\n",
        "import os\n",
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "class DataPreparation:\n",
        "  def __init__(self, content_list = None, command_source = None, save_dir = 'data'):\n",
        "    self.content_list = content_list # (Topic, ID on google drive)\n",
        "    self.command_source = command_source\n",
        "    self.save_dir = save_dir\n",
        "\n",
        "    os.makedirs(self.save_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(self.save_dir, 'content'), exist_ok = True)\n",
        "    os.makedirs(os.path.join(self.save_dir, 'command'), exist_ok = True)\n",
        "\n",
        "\n",
        "  def download_content(self) -> list[str]:\n",
        "    list_content_info = []\n",
        "    try:\n",
        "      for content_name, content_source in self.content_list:\n",
        "        url = f'https://drive.google.com/uc?id={content_source}'\n",
        "\n",
        "        output_path = os.path.join(self.save_dir, 'content', f'{content_name}.csv')\n",
        "        gdown.download(url, output_path, quiet=False)\n",
        "\n",
        "        list_content_info.append((content_name, output_path))\n",
        "      return list_content_info\n",
        "\n",
        "    except Exception as e:\n",
        "          print(f\"Error downloading {content_source}: {e}\")\n",
        "\n",
        "\n",
        "  def download_command(self) -> str:\n",
        "    try:\n",
        "      url = f'https://drive.google.com/uc?id={self.command_source}'\n",
        "\n",
        "      output_path = os.path.join(self.save_dir, 'command', 'command.csv')\n",
        "      gdown.download(url, output_path, quiet=False)\n",
        "\n",
        "      return output_path # expect csv format\n",
        "\n",
        "    except:\n",
        "      print(f\"Error downloading {self.command_source}\")\n",
        "\n",
        "\n",
        "  def get_content(self, list_content_info) -> dict:\n",
        "    content_dict = {}\n",
        "    for type_name, content_path in list_content_info:\n",
        "        df = pd.read_csv(content_path)\n",
        "        contents = [f\"{row['content']}\" for _, row in df.iterrows()]\n",
        "        content_dict[type_name] = contents\n",
        "\n",
        "    return content_dict\n",
        "\n",
        "  def get_command(self, command_path) -> list:\n",
        "    df = pd.read_csv(command_path)\n",
        "    commands = [f\"{row['command']}\" for _, row in df.iterrows()]\n",
        "\n",
        "    return commands\n",
        "\n",
        "  def run_pipeline(self, download_content = True, download_command = True):\n",
        "    if download_content:\n",
        "      list_content_info = self.download_content()\n",
        "    else:\n",
        "      content_dir = os.path.join(self.save_dir, \"content\")\n",
        "      list_content_info = [\n",
        "          (os.path.splitext(f)[0], os.path.join(content_dir, f))\n",
        "          for f in os.listdir(content_dir)\n",
        "      ]\n",
        "\n",
        "    if download_command:\n",
        "      command_path = self.download_command()\n",
        "    else:\n",
        "      command_path = os.path.join(self.save_dir, 'command', 'command.csv')\n",
        "\n",
        "    content_dict = self.get_content(list_content_info)\n",
        "    commands = self.get_command(command_path)\n",
        "\n",
        "    return content_dict, commands"
      ],
      "metadata": {
        "id": "myz2PSxbA1_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class PromptGenerator:\n",
        "  def __init__(self, num_samples_command: int, num_samples_content: int,\n",
        "               chain_length: int, prompt_dir: str, prompt_types: list,\n",
        "               list_corpus: dict[list[str]], list_command: list[str],\n",
        "               list_position: list[str], generated_nums: int, prompt_dict: dict):\n",
        "    self.num_samples_command = num_samples_command\n",
        "    self.num_samples_content = num_samples_content\n",
        "    self.chain_length = chain_length # for chain case\n",
        "    self.prompt_dir = prompt_dir\n",
        "    self.prompt_types = prompt_types\n",
        "    self.list_corpus = list_corpus\n",
        "    self.list_command = list_command\n",
        "    self.list_position = list_position\n",
        "    self.generated_nums = generated_nums\n",
        "    self.prompt_dict = prompt_dict\n",
        "\n",
        "  def content_sample(self):\n",
        "    # corpus = list of list\n",
        "    sample_list = []\n",
        "    # sampling content from each data corpus\n",
        "    for corpus in self.list_corpus:\n",
        "      sample_list.append(random.sample(self.list_corpus[corpus], self.num_samples_content))\n",
        "\n",
        "    return sample_list\n",
        "\n",
        "  def command_sample(self):\n",
        "    sample = random.sample(self.list_command, self.num_samples_command)\n",
        "    return sample\n",
        "\n",
        "  def get_prompt(self, prompt_type, sampled_command, sampled_contents):\n",
        "    prompt_dict = self.prompt_dict # get from config\n",
        "\n",
        "    prompt_template = prompt_dict[prompt_type]\n",
        "    if prompt_type in (\"single_mix\", \"chain_mix\"):\n",
        "      command_position = self.position_sample()\n",
        "      prompt = prompt_template.format(command_list = sampled_command,\n",
        "                                      content_list = sampled_contents,\n",
        "                                      generated_nums = self.generated_nums,\n",
        "                                      command_position = command_position)\n",
        "    else:\n",
        "      prompt = prompt_template.format(command_list = sampled_command,\n",
        "                                      content_list = sampled_contents,\n",
        "                                      generated_nums = self.generated_nums)\n",
        "\n",
        "    return prompt\n",
        "\n",
        "  def position_sample(self):\n",
        "    sample = random.sample(self.list_position, 3)\n",
        "\n",
        "    joiners = [\"and/or\" for _ in range(3)]\n",
        "    sample = [f\"{pos} {joiner}\" for pos, joiner in zip(sample, joiners)]\n",
        "    sample = \" \".join(sample)\n",
        "    return sample\n",
        "\n",
        "  def generate_prompt(self):\n",
        "    prompts = {}\n",
        "    for prompt_type in self.prompt_types:\n",
        "      sampled_command = self.command_sample()\n",
        "      sampled_contents = self.content_sample()\n",
        "\n",
        "      prompt = self.get_prompt(prompt_type,\n",
        "                              sampled_command = sampled_command,\n",
        "                              sampled_contents = sampled_contents)\n",
        "\n",
        "      prompts[prompt_type] = prompt\n",
        "    return prompts\n"
      ],
      "metadata": {
        "id": "gyRrIfBAHkTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import uuid\n",
        "\n",
        "class TextGenerator:\n",
        "  def __init__(self, model, temperature):\n",
        "    self.model = model\n",
        "    self.temperature = temperature # sau có thể sửa thành 1 file config\n",
        "\n",
        "    try:\n",
        "      api_key = self.get_api_key(\"colab\")\n",
        "      self.client = OpenAI(api_key=api_key)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f'fail at init model!')\n",
        "      raise e\n",
        "\n",
        "  def get_api_key(self, env_type: str):\n",
        "    match env_type:\n",
        "      case \"colab\":\n",
        "        return userdata.get(\"OPENAI_API_KEY\")\n",
        "      case \"local\":\n",
        "        return os.getenv(\"OPENAI_API_KEY\")\n",
        "      # add more case there\n",
        "\n",
        "  def generate(self, prompt):\n",
        "    # just for openai\n",
        "    response = self.client.responses.create(\n",
        "        model=self.model,\n",
        "        input = prompt,\n",
        "        temperature=self.temperature,\n",
        "    )\n",
        "    return response.output[0].content[0].text\n",
        "\n",
        "  def create_df(self, parsed_data):\n",
        "    rows = []\n",
        "\n",
        "    for main_type, items in parsed_data.items():\n",
        "        for idx, item in enumerate(items):\n",
        "\n",
        "            id = uuid.uuid4().hex[:8]\n",
        "\n",
        "            if isinstance(item, dict):\n",
        "                # Structured format with segments\n",
        "                text = item.get('text', '')\n",
        "                segments = item.get('segments', [])\n",
        "\n",
        "                rows.append({\n",
        "                    'id': id,\n",
        "                    'text': text,\n",
        "                    'type': main_type,\n",
        "                    'segments': segments if segments else None,\n",
        "                    'has_segments': len(segments) > 0\n",
        "                })\n",
        "            else:\n",
        "                # Simple string format (fallback)\n",
        "                rows.append({\n",
        "                    'id': id,\n",
        "                    'text': item,\n",
        "                    'type': main_type,\n",
        "                    'segments': None,\n",
        "                    'has_segments': False\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "hF8HFfaoIRrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "def clean_json_string(raw_output):\n",
        "    # Bỏ phần ```json và ```\n",
        "    cleaned = re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw_output.strip())\n",
        "    return cleaned\n",
        "\n",
        "def parse_generated_json(raw_output):\n",
        "    cleaned = clean_json_string(raw_output)\n",
        "    return json.loads(cleaned)"
      ],
      "metadata": {
        "id": "zpmSywnpIp_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main config\n",
        "prompt_gen_param = {\n",
        "    \"num_samples_command\": 5,\n",
        "    \"num_samples_content\": 5,\n",
        "    \"chain_length\": 3,\n",
        "    \"prompt_dir\": \"prompt\",\n",
        "    \"prompt_types\": ['non_active', 'single_active', 'single_mix', 'chain_active', 'chain_mix'],\n",
        "    \"generated_nums\": 4,\n",
        "}\n",
        "\n",
        "text_gen_param = {\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"temperature\": 1,\n",
        "}\n",
        "\n",
        "LOOP = 5\n",
        "FILE_NUM = 50\n",
        "START = 0"
      ],
      "metadata": {
        "id": "0nPZHNmxJ3Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def main(download = True, export_folder = 'command_text'):\n",
        "  os.makedirs(export_folder, exist_ok = True)\n",
        "  dp = DataPreparation(content_list = content_list,\n",
        "                       command_source = command_source)\n",
        "\n",
        "  if download:\n",
        "    content_dict, commands = dp.run_pipeline()\n",
        "  else:\n",
        "    content_dict, commands = dp.run_pipeline(download_content = False, download_command = False)\n",
        "\n",
        "  pg = PromptGenerator(list_corpus = content_dict,\n",
        "                       list_command = commands,\n",
        "                       list_position = list_position,\n",
        "                       prompt_dict= PROMPT_CORPUS,\n",
        "                       **prompt_gen_param)\n",
        "\n",
        "  tg = TextGenerator(**text_gen_param)\n",
        "\n",
        "  list_command = []\n",
        "\n",
        "  for i in tqdm(range(START, START + FILE_NUM)):\n",
        "      for _ in range(LOOP):\n",
        "          prompts = pg.generate_prompt()\n",
        "          for prompt_type, prompt in prompts.items():\n",
        "              generated_output = tg.generate(prompt)\n",
        "              parsed_data = parse_generated_json(generated_output)\n",
        "\n",
        "              df_commands = tg.create_df(parsed_data)\n",
        "              list_command.append(df_commands)\n",
        "\n",
        "      list_command_df = pd.concat(list_command, ignore_index=True)\n",
        "      path = os.path.join(export_folder, f'commands_{i}.csv')\n",
        "      list_command.to_csv(path, idnex=False)\n",
        "    list_command_df.to_csv('synthesis_command.csv', index=False)\n"
      ],
      "metadata": {
        "id": "olYX9Dx-I1mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(download = True)"
      ],
      "metadata": {
        "id": "L_SXCWrAjEyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3645b68-1284-43d1-c8a3-aad1a562c1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NIPjwYGi5b1xuB_e8y1ks_oGZ_obalny\n",
            "To: /content/data/content/app.csv\n",
            "100%|██████████| 622/622 [00:00<00:00, 1.76MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19xDdO_BZmpZLHlbXN-aNuEFU_xvqzFjn\n",
            "To: /content/data/content/movie.csv\n",
            "100%|██████████| 250k/250k [00:00<00:00, 9.50MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-_bVYQUV8DJ4KvG5j7cK0ZcvJY6s9dre\n",
            "To: /content/data/content/song.csv\n",
            "100%|██████████| 2.50M/2.50M [00:00<00:00, 38.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lZcb1cKaYwCS9wqHf8PXct-cpxAvM2Oz\n",
            "To: /content/data/content/tv.csv\n",
            "100%|██████████| 6.27k/6.27k [00:00<00:00, 11.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zHhi08gxGqc_qGTxoQH-YIP7vuzmu7v3\n",
            "To: /content/data/command/command.csv\n",
            "100%|██████████| 1.35k/1.35k [00:00<00:00, 3.10MB/s]\n",
            "100%|██████████| 50/50 [1:30:44<00:00, 108.89s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jOTaWFmV6QN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}