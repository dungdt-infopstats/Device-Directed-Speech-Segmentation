{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13004856,
          "sourceType": "datasetVersion",
          "datasetId": 8232994
        },
        {
          "sourceId": 13049719,
          "sourceType": "datasetVersion",
          "datasetId": 8263642
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Transcribe-Output-DDSS",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dungdt-infopstats/Device-Directed-Speech-Segmentation/blob/main/src_prototype/Transcribe_Output_DDSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "EREG9oh_eZoi"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "tridungdo_test_100_150_path = kagglehub.dataset_download('tridungdo/test-100-150')\n",
        "tridungdo_wav2vec2_asr_100_150_true_outputs_path = kagglehub.dataset_download('tridungdo/wav2vec2-asr-100-150-true-outputs')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "sIRlIviHeZok"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install pydub\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:47:57.811651Z",
          "iopub.execute_input": "2025-09-13T18:47:57.812202Z",
          "iopub.status.idle": "2025-09-13T18:48:15.387686Z",
          "shell.execute_reply.started": "2025-09-13T18:47:57.812176Z",
          "shell.execute_reply": "2025-09-13T18:48:15.386972Z"
        },
        "id": "MgbpSlxTeZol"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:48:15.388606Z",
          "iopub.execute_input": "2025-09-13T18:48:15.388848Z",
          "iopub.status.idle": "2025-09-13T18:48:15.393038Z",
          "shell.execute_reply.started": "2025-09-13T18:48:15.388827Z",
          "shell.execute_reply": "2025-09-13T18:48:15.39228Z"
        },
        "id": "jvp8k49meZol"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from pydub import AudioSegment\n",
        "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
        "from multiprocessing import Pool, cpu_count, Manager\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "import shutil\n",
        "import pickle\n",
        "from functools import partial\n",
        "\n",
        "# ==========================================================\n",
        "# Helper: Convert vector -> time ranges\n",
        "# ==========================================================\n",
        "def vector_to_time_ranges(\n",
        "    vector: List[int],\n",
        "    frame_dur: float,\n",
        "    hop_dur: float,\n",
        "    pad: int = 15\n",
        ") -> List[Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Convert binary vector (0/1) -> list of {\"start\", \"end\"} in seconds.\n",
        "    Merge segments when short gaps exist (controlled by pad).\n",
        "    \"\"\"\n",
        "    ranges = []\n",
        "    n = len(vector)\n",
        "    i = 0\n",
        "\n",
        "    while i < n:\n",
        "        if vector[i] == 1:\n",
        "            start = i * hop_dur\n",
        "            j = i\n",
        "            while j < n and any(vector[max(0, j - pad):min(n, j + pad + 1)]):\n",
        "                j += 1\n",
        "            end = j * hop_dur + frame_dur\n",
        "            ranges.append({\"start\": start, \"end\": end})\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return ranges\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Helper: Load audio and slice\n",
        "# ==========================================================\n",
        "def load_audio_as_pydub(path: str, sr: Optional[int] = None) -> AudioSegment:\n",
        "    \"\"\"Load audio file using pydub with optional sample rate conversion.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Audio file not found: {path}\")\n",
        "\n",
        "    audio = AudioSegment.from_file(path)\n",
        "    if sr is not None and audio.frame_rate != sr:\n",
        "        audio = audio.set_frame_rate(sr)\n",
        "    return audio\n",
        "\n",
        "def slice_audio_segment(audio: AudioSegment, start: float, end: float) -> AudioSegment:\n",
        "    \"\"\"Slice audio segment from start to end (in seconds).\"\"\"\n",
        "    start_ms = max(0, int(start * 1000))\n",
        "    end_ms = min(len(audio), int(end * 1000))\n",
        "    return audio[start_ms:end_ms]\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Global function for transcribing segments (needed for multiprocessing)\n",
        "# ==========================================================\n",
        "def transcribe_segment_worker(audio_bytes: bytes, model_size: str, device: str, batch_mode: bool = True) -> str:\n",
        "    \"\"\"Transcribe a single audio segment in a worker process.\"\"\"\n",
        "    try:\n",
        "        # Initialize model in worker process\n",
        "        model = WhisperModel(model_size, device=device)\n",
        "        if batch_mode:\n",
        "            model = BatchedInferencePipeline(model=model)\n",
        "\n",
        "        # Create temporary file for this segment\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
        "            tmp_path = tmp_file.name\n",
        "            tmp_file.write(audio_bytes)\n",
        "\n",
        "        try:\n",
        "            # Transcribe using Whisper\n",
        "            if not batch_mode:\n",
        "                segments, _ = model.transcribe(tmp_path)\n",
        "            else:\n",
        "                segments, _ = model.transcribe(tmp_path, batch_size=128)\n",
        "            text = \" \".join([seg.text for seg in segments]).strip()\n",
        "\n",
        "            return text\n",
        "        finally:\n",
        "            if os.path.exists(tmp_path):\n",
        "                os.unlink(tmp_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing segment: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def process_segment_worker(args: Tuple[bytes, Dict[str, float], int, str, str, str, str, bool]) -> Dict[str, Any]:\n",
        "    \"\"\"Process a single segment in a worker process.\"\"\"\n",
        "    audio_bytes, time_range, idx, save_segments_dir, base_name, model_size, device, batch_mode = args\n",
        "\n",
        "    try:\n",
        "        # Reconstruct audio segment from bytes\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
        "            tmp_path = tmp_file.name\n",
        "            tmp_file.write(audio_bytes)\n",
        "\n",
        "        audio_seg = AudioSegment.from_file(tmp_path)\n",
        "        os.unlink(tmp_path)\n",
        "\n",
        "        seg = slice_audio_segment(audio_seg, time_range[\"start\"], time_range[\"end\"])\n",
        "\n",
        "        # Save segment if requested\n",
        "        if save_segments_dir:\n",
        "            os.makedirs(save_segments_dir, exist_ok=True)\n",
        "            seg_name = f\"{base_name}_segment_{idx}.wav\"\n",
        "            seg.export(os.path.join(save_segments_dir, seg_name), format=\"wav\")\n",
        "\n",
        "        if len(seg) < 100:  # too short\n",
        "            return {\n",
        "                \"segment_index\": idx,\n",
        "                \"start\": time_range[\"start\"],\n",
        "                \"end\": time_range[\"end\"],\n",
        "                \"recognized_text\": \"\",\n",
        "            }\n",
        "\n",
        "        # Convert segment to bytes for transcription\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmp_file:\n",
        "            seg.export(tmp_file.name, format=\"wav\")\n",
        "            with open(tmp_file.name, 'rb') as f:\n",
        "                seg_bytes = f.read()\n",
        "\n",
        "        hyp = transcribe_segment_worker(seg_bytes, model_size, device, batch_mode)\n",
        "\n",
        "        return {\n",
        "            \"segment_index\": idx,\n",
        "            \"start\": time_range[\"start\"],\n",
        "            \"end\": time_range[\"end\"],\n",
        "            \"recognized_text\": hyp,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing segment {idx}: {e}\")\n",
        "        return {\n",
        "            \"segment_index\": idx,\n",
        "            \"start\": time_range[\"start\"],\n",
        "            \"end\": time_range[\"end\"],\n",
        "            \"recognized_text\": \"\",\n",
        "        }\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Process single file worker (for file-level parallelization)\n",
        "# ==========================================================\n",
        "def process_file_worker(args: Tuple[str, Dict[str, Any]]) -> pd.DataFrame:\n",
        "    \"\"\"Process a single file in a worker process.\"\"\"\n",
        "    audio_path, params = args\n",
        "\n",
        "    try:\n",
        "        # Extract parameters\n",
        "        sr = params.get('sr')\n",
        "        vector = params.get('vector')\n",
        "        frame_dur = params.get('frame_dur', 0.025)\n",
        "        hop_dur = params.get('hop_dur', 0.01)\n",
        "        pad = params.get('pad', 15)\n",
        "        model_size = params.get('model_size', 'medium')\n",
        "        device = params.get('device', 'cpu')\n",
        "        batch_mode = params.get('batch_mode', True)\n",
        "        save_segments_dir = params.get('save_segments_dir')\n",
        "        fallback_on_no_segments = params.get('fallback_on_no_segments', True)\n",
        "        segment_level_parallel = params.get('segment_level_parallel', False)\n",
        "        max_workers = params.get('max_workers', 4)\n",
        "\n",
        "        # Load audio\n",
        "        try:\n",
        "            audio_seg = load_audio_as_pydub(audio_path, sr)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading audio {audio_path}: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Get time ranges\n",
        "        time_ranges = vector_to_time_ranges(vector, frame_dur, hop_dur, pad)\n",
        "\n",
        "        if not time_ranges:\n",
        "            print(f\"No active segments found for {audio_path}\")\n",
        "            if not fallback_on_no_segments:\n",
        "                return pd.DataFrame()\n",
        "            time_ranges = [{\"start\": 0, \"end\": 0}]\n",
        "\n",
        "        base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "        # Convert audio to bytes for passing to workers\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmp_file:\n",
        "            audio_seg.export(tmp_file.name, format=\"wav\")\n",
        "            with open(tmp_file.name, 'rb') as f:\n",
        "                audio_bytes = f.read()\n",
        "\n",
        "        results = []\n",
        "\n",
        "        if segment_level_parallel and len(time_ranges) > 1:\n",
        "            # Process segments in parallel\n",
        "            args_list = [\n",
        "                (audio_bytes, time_range, idx, save_segments_dir, base_name, model_size, device, batch_mode)\n",
        "                for idx, time_range in enumerate(time_ranges)\n",
        "            ]\n",
        "\n",
        "            with Pool(processes=min(max_workers, len(args_list))) as pool:\n",
        "                results = pool.map(process_segment_worker, args_list)\n",
        "        else:\n",
        "            # Process segments sequentially within the file\n",
        "            for idx, time_range in enumerate(time_ranges):\n",
        "                args = (audio_bytes, time_range, idx, save_segments_dir, base_name, model_size, device, batch_mode)\n",
        "                result = process_segment_worker(args)\n",
        "                results.append(result)\n",
        "\n",
        "        results.sort(key=lambda x: x[\"segment_index\"])\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {audio_path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Multi-processing ASR Processor\n",
        "# ==========================================================\n",
        "class ASRProcessor:\n",
        "    def __init__(self, model_size=\"medium\", device=\"cpu\", max_workers=None):\n",
        "        self.model_size = model_size\n",
        "        self.device = device\n",
        "        self.max_workers = max_workers or cpu_count()\n",
        "\n",
        "    def process_file(\n",
        "        self,\n",
        "        audio_path: str,\n",
        "        sr: Optional[int],\n",
        "        vector: List[int],\n",
        "        frame_dur: float,\n",
        "        hop_dur: float,\n",
        "        pad: int,\n",
        "        show_progress: bool = True,\n",
        "        fallback_on_no_segments: bool = True,\n",
        "        save_segments_dir: Optional[str] = None,\n",
        "        segment_level_parallel: bool = False\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"Process a single file (wrapper for compatibility).\"\"\"\n",
        "        params = {\n",
        "            'sr': sr,\n",
        "            'vector': vector,\n",
        "            'frame_dur': frame_dur,\n",
        "            'hop_dur': hop_dur,\n",
        "            'pad': pad,\n",
        "            'model_size': self.model_size,\n",
        "            'device': self.device,\n",
        "            'batch_mode': True,\n",
        "            'save_segments_dir': save_segments_dir,\n",
        "            'fallback_on_no_segments': fallback_on_no_segments,\n",
        "            'segment_level_parallel': segment_level_parallel,\n",
        "            'max_workers': self.max_workers\n",
        "        }\n",
        "\n",
        "        return process_file_worker((audio_path, params))\n",
        "\n",
        "    def process_multiple_files(\n",
        "        self,\n",
        "        file_params_list: List[Tuple[str, Dict[str, Any]]],\n",
        "        show_progress: bool = True,\n",
        "        file_level_parallel: bool = True\n",
        "    ) -> List[pd.DataFrame]:\n",
        "        \"\"\"Process multiple files with multiprocessing.\"\"\"\n",
        "        if file_level_parallel and len(file_params_list) > 1:\n",
        "            # Process files in parallel\n",
        "            with Pool(processes=min(self.max_workers, len(file_params_list))) as pool:\n",
        "                if show_progress:\n",
        "                    results = []\n",
        "                    with tqdm(total=len(file_params_list), desc=\"Processing files\") as pbar:\n",
        "                        for result in pool.imap(process_file_worker, file_params_list):\n",
        "                            results.append(result)\n",
        "                            pbar.update(1)\n",
        "                else:\n",
        "                    results = pool.map(process_file_worker, file_params_list)\n",
        "            return results\n",
        "        else:\n",
        "            # Process files sequentially\n",
        "            results = []\n",
        "            iterator = tqdm(file_params_list, desc=\"Processing files\") if show_progress else file_params_list\n",
        "            for file_params in iterator:\n",
        "                result = process_file_worker(file_params)\n",
        "                results.append(result)\n",
        "            return results\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Safe parsing function\n",
        "# ==========================================================\n",
        "def safe_parse_predictions(preds_str: str) -> Optional[List[int]]:\n",
        "    try:\n",
        "        if isinstance(preds_str, (list, np.ndarray)):\n",
        "            return list(preds_str)\n",
        "        if isinstance(preds_str, str):\n",
        "            try:\n",
        "                return ast.literal_eval(preds_str)\n",
        "            except:\n",
        "                return eval(preds_str)\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing predictions: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Process DataFrame template with multiprocessing\n",
        "# ==========================================================\n",
        "def process_from_template_df(\n",
        "    df: pd.DataFrame,\n",
        "    model_size: str = \"medium\",\n",
        "    device: str = \"cpu\",\n",
        "    frame_dur: float = 0.025,\n",
        "    hop_dur: float = 0.01,\n",
        "    pad: int = 15,\n",
        "    max_workers: int = None,\n",
        "    audio_root_path: str = \"/kaggle/input/ddss-aug-ratio-test/test\",\n",
        "    fallback_on_no_segments: bool = True,\n",
        "    file_level_parallel: bool = True,\n",
        "    segment_level_parallel: bool = False,\n",
        "    save_segments_dir: Optional[str] = None\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process DataFrame with multiprocessing support.\n",
        "\n",
        "    Args:\n",
        "        file_level_parallel: If True, process files in parallel\n",
        "        segment_level_parallel: If True, process segments within each file in parallel\n",
        "    \"\"\"\n",
        "    max_workers = max_workers or cpu_count()\n",
        "    print(f\"Initializing ASR Processor with model_size={model_size}, device={device}, max_workers={max_workers}\")\n",
        "    print(f\"File-level parallel: {file_level_parallel}, Segment-level parallel: {segment_level_parallel}\")\n",
        "\n",
        "    processor = ASRProcessor(model_size=model_size, device=device, max_workers=max_workers)\n",
        "\n",
        "    # Prepare file parameters list\n",
        "    file_params_list = []\n",
        "    for idx, row in df.iterrows():\n",
        "        try:\n",
        "            audio_id = row[\"id\"]\n",
        "            folder_name = row.get(\"id_f\", \"\")\n",
        "            audio_path = os.path.join(audio_root_path, folder_name, f\"{audio_id}.wav\")\n",
        "\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(f\"Warning: Audio file not found: {audio_path}\")\n",
        "                continue\n",
        "\n",
        "            preds = safe_parse_predictions(row[\"preds\"])\n",
        "            if preds is None:\n",
        "                print(f\"Error parsing predictions for {audio_id}\")\n",
        "                continue\n",
        "\n",
        "            params = {\n",
        "                'sr': row.get(\"sampling_rate\", None),\n",
        "                'vector': preds,\n",
        "                'frame_dur': frame_dur,\n",
        "                'hop_dur': hop_dur,\n",
        "                'pad': pad,\n",
        "                'model_size': model_size,\n",
        "                'device': device,\n",
        "                'batch_mode': True,\n",
        "                'save_segments_dir': save_segments_dir,\n",
        "                'fallback_on_no_segments': fallback_on_no_segments,\n",
        "                'segment_level_parallel': segment_level_parallel,\n",
        "                'max_workers': max_workers,\n",
        "                'row_data': row.to_dict()  # Store row data for later use\n",
        "            }\n",
        "\n",
        "            file_params_list.append((audio_path, params))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing row {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not file_params_list:\n",
        "        print(\"Warning: No valid files to process\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Processing {len(file_params_list)} files...\")\n",
        "\n",
        "    # Process files\n",
        "    results_list = processor.process_multiple_files(\n",
        "        file_params_list,\n",
        "        show_progress=True,\n",
        "        file_level_parallel=file_level_parallel\n",
        "    )\n",
        "\n",
        "    # Combine results and add original row data\n",
        "    all_results = []\n",
        "    for i, df_segments in enumerate(results_list):\n",
        "        if df_segments.empty:\n",
        "            continue\n",
        "\n",
        "        # Get original row data\n",
        "        _, params = file_params_list[i]\n",
        "        row_data = params['row_data']\n",
        "\n",
        "        # Add original columns to segments\n",
        "        for col, value in row_data.items():\n",
        "            if col not in df_segments.columns:\n",
        "                # Convert complex types to string to avoid length mismatch\n",
        "                if isinstance(value, (list, np.ndarray, dict)):\n",
        "                    value = str(value)\n",
        "                df_segments[col] = value\n",
        "\n",
        "        all_results.append(df_segments)\n",
        "\n",
        "    if not all_results:\n",
        "        print(\"Warning: No results to concatenate\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    final_df = pd.concat(all_results, ignore_index=True)\n",
        "    print(f\"Final dataset shape: {final_df.shape}\")\n",
        "    return final_df\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Save results\n",
        "# ==========================================================\n",
        "def save_results(df: pd.DataFrame, output_path: str):\n",
        "    if df.empty:\n",
        "        print(\"Warning: DataFrame is empty, nothing to save\")\n",
        "        return\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:48:15.395037Z",
          "iopub.execute_input": "2025-09-13T18:48:15.395463Z",
          "iopub.status.idle": "2025-09-13T18:48:22.298915Z",
          "shell.execute_reply.started": "2025-09-13T18:48:15.395439Z",
          "shell.execute_reply": "2025-09-13T18:48:22.298154Z"
        },
        "id": "GVHY2htLeZom"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "with open(\"/kaggle/input/wav2vec2-asr-100-150-true-outputs/wav2vec2-asr-100-150-true.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:58:33.49652Z",
          "iopub.execute_input": "2025-09-13T18:58:33.496835Z",
          "iopub.status.idle": "2025-09-13T18:58:43.209336Z",
          "shell.execute_reply.started": "2025-09-13T18:58:33.496805Z",
          "shell.execute_reply": "2025-09-13T18:58:43.208513Z"
        },
        "id": "DYpJOxVseZon"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5"
      ],
      "metadata": {
        "trusted": true,
        "id": "buL5DtNZeZoo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# threshold\n",
        "\n",
        "df['preds'] = df['outputs'].apply(lambda x: [int(v >= threshold) for v in x])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:58:48.315993Z",
          "iopub.execute_input": "2025-09-13T18:58:48.316479Z",
          "iopub.status.idle": "2025-09-13T18:58:50.388322Z",
          "shell.execute_reply.started": "2025-09-13T18:58:48.316458Z",
          "shell.execute_reply": "2025-09-13T18:58:50.38753Z"
        },
        "id": "tTLb12RCeZoo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['id_f'] = df['id'].str.rsplit('_', n = 1).str[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:58:52.085405Z",
          "iopub.execute_input": "2025-09-13T18:58:52.085772Z",
          "iopub.status.idle": "2025-09-13T18:58:53.358213Z",
          "shell.execute_reply.started": "2025-09-13T18:58:52.085742Z",
          "shell.execute_reply": "2025-09-13T18:58:53.357626Z"
        },
        "id": "j8RpWNrheZoo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Main execution\n",
        "# ==========================================================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Starting ASR evaluation...\")\n",
        "        results_df = process_from_template_df(\n",
        "            df=df,  # must define 'merge'\n",
        "            model_size=\"base\",\n",
        "            frame_dur = 0.025,\n",
        "            hop_dur = 0.01,\n",
        "            pad = 15,\n",
        "            device=\"cuda\",\n",
        "            max_workers=4,\n",
        "            audio_root_path=\"/kaggle/input/test-100-150/test\",\n",
        "            fallback_on_no_segments=True,\n",
        "            file_level_parallel=True,\n",
        "            segment_level_parallel=False,\n",
        "            save_segments_dir=\"segment\"\n",
        "        )\n",
        "        if not results_df.empty:\n",
        "            save_results(results_df, \"asr_res_100_150.csv\")\n",
        "            result_df.to_json('asr_res_100_150.json', orient = 'records', force_ascii=False)\n",
        "        else:\n",
        "            print(\"No results to save.\")\n",
        "\n",
        "        save_dir = 'save'\n",
        "        if os.path.exists(save_dir):\n",
        "            shutil.make_archive(\"cut_segments_archive\", \"zip\", save_dir)\n",
        "            print(\"Segments saved and zipped to cut_segments_archive.zip\")\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Make sure the 'merge' DataFrame is defined before running this script.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:58:56.468546Z",
          "iopub.execute_input": "2025-09-13T18:58:56.469136Z",
          "iopub.status.idle": "2025-09-13T19:00:20.984705Z",
          "shell.execute_reply.started": "2025-09-13T18:58:56.469113Z",
          "shell.execute_reply": "2025-09-13T19:00:20.983497Z"
        },
        "id": "wem0Ax0ueZop"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "save_dir = 'save'\n",
        "if os.path.exists(save_dir):\n",
        "    shutil.make_archive(\"cut_segments_archive\", \"zip\", save_dir)\n",
        "    print(\"Segments saved and zipped to cut_segments_archive.zip\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T18:56:52.8846Z",
          "iopub.status.idle": "2025-09-13T18:56:52.884946Z",
          "shell.execute_reply.started": "2025-09-13T18:56:52.884789Z",
          "shell.execute_reply": "2025-09-13T18:56:52.884807Z"
        },
        "id": "wuqVHGY4eZop"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "vGr-82ZLeZop"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}