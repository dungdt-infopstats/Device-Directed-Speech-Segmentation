{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuk5nqpeEjTKo8RAhme9YR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10udCryp7/TV-command-synthesis/blob/main/notebooksDataSynthesisPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation & Preparation\n",
        "- install dependencies\n",
        "- download data"
      ],
      "metadata": {
        "id": "J_MloylnxlQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "1SI6MC5Yx2rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F5-TTS\n",
        "!pip install -q f5-tts"
      ],
      "metadata": {
        "id": "fKASAG5GvxlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "7Np_ZF5Vx5a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference Speech\n",
        "!gdown 1uTreohCIiYSlrQTa3fuH1_IQjdeW1SaE --quiet\n",
        "# Reference Meta (including Text)\n",
        "!gdown 1PBs6r3cqhFxWzy9s5wrGpF6-5ZnoOWxE --quiet\n",
        "\n",
        "!unzip -q /content/audio.zip -d /content/audio\n",
        "!unzip -q /content/json.zip -d /content/json"
      ],
      "metadata": {
        "id": "2jtobwUicWPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Command Synthesis\n",
        "Return:\n",
        "- df_commands\n",
        "- commands.csv (optional)"
      ],
      "metadata": {
        "id": "ThNMx7RrRo87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List TV command templates"
      ],
      "metadata": {
        "id": "n2ZtUTeDy7uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tv_command_templates = [\n",
        "    # Power control\n",
        "    \"turn on the TV\",\n",
        "    \"turn off the TV\",\n",
        "    \"restart the TV\",\n",
        "    \"put the TV in sleep mode\",\n",
        "\n",
        "    # Volume control\n",
        "    \"increase the volume\",\n",
        "    \"increase the volume to [level]\",\n",
        "    \"decrease the volume\",\n",
        "    \"decrease the volume to [level]\",\n",
        "    \"set volume to [level]\",\n",
        "    \"mute the TV\",\n",
        "    \"unmute the TV\",\n",
        "    \"set the volume to maximum\",\n",
        "    \"set the volume to minimum\",\n",
        "\n",
        "    # Channel control\n",
        "    \"change the channel\",\n",
        "    \"next channel\",\n",
        "    \"previous channel\",\n",
        "    \"go to channel [channel number]\",\n",
        "    \"switch to channel [channel name]\",\n",
        "    \"show me [channel name]\",\n",
        "\n",
        "    # App control\n",
        "    \"open [app name]\",\n",
        "    \"launch [app name]\",\n",
        "    \"close [app name]\",\n",
        "    \"switch to [app name]\",\n",
        "    \"search on [app name] for [query]\",\n",
        "\n",
        "    # Media playback\n",
        "    \"play\",\n",
        "    \"pause\",\n",
        "    \"resume\",\n",
        "    \"stop\",\n",
        "    \"rewind\",\n",
        "    \"rewind [seconds] seconds\",\n",
        "    \"fast forward\",\n",
        "    \"fast forward [seconds] seconds\",\n",
        "    \"skip intro\",\n",
        "    \"skip to next episode\",\n",
        "    \"go back to previous episode\",\n",
        "\n",
        "    # Subtitles and language\n",
        "    \"turn on subtitles\",\n",
        "    \"turn off subtitles\",\n",
        "    \"change subtitle language to [language]\",\n",
        "    \"change audio language to [language]\",\n",
        "\n",
        "    # Input source\n",
        "    \"switch to [input source]\",\n",
        "    \"change input to [input source]\",\n",
        "    \"go to HDMI [number]\",\n",
        "    \"switch to AV mode\",\n",
        "\n",
        "    # Picture and audio settings\n",
        "    \"set brightness to [level]\",\n",
        "    \"set contrast to [level]\",\n",
        "    \"enable night mode\",\n",
        "    \"disable night mode\",\n",
        "    \"enable game mode\",\n",
        "    \"disable game mode\",\n",
        "    \"set picture mode to [mode name]\",\n",
        "    \"set sound mode to [mode name]\",\n",
        "\n",
        "    # Smart features\n",
        "    \"record this show\",\n",
        "    \"show the TV guide\",\n",
        "    \"what’s playing now\",\n",
        "    \"show me recommendations\",\n",
        "    \"add this to my watchlist\",\n",
        "    \"rate this show [rating]\",\n",
        "    \"enable sleep timer for [minutes] minutes\",\n",
        "    \"remind me when [show name] starts\",\n",
        "\n",
        "    # Navigation\n",
        "    \"go back to home screen\",\n",
        "    \"open settings\",\n",
        "    \"scroll up\",\n",
        "    \"scroll down\",\n",
        "    \"select this option\",\n",
        "]"
      ],
      "metadata": {
        "id": "ZAIyW5MwFcZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content list\n",
        "- song name\n",
        "- movie name\n",
        "- app name"
      ],
      "metadata": {
        "id": "bgODJk2vRrzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# song's names from spotify\n",
        "song_dataset = pd.read_csv(\"hf://datasets/vishnupriyavr/spotify-million-song-dataset/spotify_millsongdata.csv\")\n",
        "# movie's names\n",
        "movie_dataset = pd.read_csv(\"hf://datasets/Pablinho/movies-dataset/9000plus.csv\")\n",
        "\n",
        "app_dataset = [\n",
        "    # 1. Video tổng hợp\n",
        "    \"YouTube\",\n",
        "    \"TikTok TV\",\n",
        "    \"Facebook Watch\",\n",
        "    \"Twitch\",\n",
        "    \"Dailymotion\",\n",
        "    \"Vimeo\",\n",
        "    \"Rumble\",\n",
        "    \"Bilibili\",\n",
        "    \"TED\",\n",
        "    \"Vevo TV\",\n",
        "\n",
        "    # 2. Xem phim/truyền hình\n",
        "    \"Netflix\",\n",
        "    \"Disney+\",\n",
        "    \"Amazon Prime Video\",\n",
        "    \"Apple TV+\",\n",
        "    \"HBO Max\",\n",
        "    \"Hulu\",\n",
        "    \"Paramount+\",\n",
        "    \"Peacock\",\n",
        "    \"Crunchyroll\",\n",
        "    \"Plex\",\n",
        "    \"Tubi TV\",\n",
        "    \"Pluto TV\",\n",
        "    \"Rakuten TV\",\n",
        "    \"Viki\",\n",
        "    \"Popcornflix\",\n",
        "\n",
        "    # 3. Nghe nhạc và radio\n",
        "    \"Spotify\",\n",
        "    \"Apple Music\",\n",
        "    \"YouTube Music\",\n",
        "    \"Amazon Music\",\n",
        "    \"Tidal\",\n",
        "    \"Deezer\",\n",
        "    \"Pandora\",\n",
        "    \"SoundCloud\",\n",
        "    \"iHeartRadio\",\n",
        "    \"TuneIn Radio\",\n",
        "\n",
        "    # 4. Truyền hình trực tiếp & thể thao\n",
        "    \"ESPN\",\n",
        "    \"DAZN\",\n",
        "    \"NBC Sports\",\n",
        "    \"CBS Sports\",\n",
        "    \"Red Bull TV\",\n",
        "    \"BBC iPlayer\",\n",
        "    \"ITVX\",\n",
        "    \"Sling TV\"\n",
        "]"
      ],
      "metadata": {
        "id": "pdDlfZkTQ02E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(app_dataset))\n",
        "print(len(song_dataset))\n",
        "print(len(movie_dataset))"
      ],
      "metadata": {
        "id": "L7g3CoKV4Tig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "autpeqOBa-oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and function"
      ],
      "metadata": {
        "id": "OIsWu1WJa_0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PROMPT\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are given the following:\n",
        "\n",
        "- A list of TV control commands: {command_list}\n",
        "- A content list that includes names of songs, TV shows, movies, apps, and artists: {content_list}\n",
        "\n",
        "Your task is to generate {generated_nums} human-like commands using the command list and the content list. The content list includes the prefix movies or artist-song to shows you their type, you should remove them when generate commands, also leverage them smartly for high human-like commands.\n",
        "Half of the commands should be **single commands**, and the other half should be **chain commands**. A chain command consists of multiple actions (up to a maximum of {chain_length} sub-commands) combined in a natural way. The final list sub-commands is extracted from full chain commands.\n",
        "\n",
        "Be creative in your generation. You should use specific content from the content list—such as names of songs, movies, TV shows, or artists—instead of generic phrases like \"this song\" or \"that movie\".\n",
        "\n",
        "Each generated command should be as **realistic and unique** as possible.\n",
        "\n",
        "Return only the generated human-like commands in the **following JSON format** (use **double quotes** for all strings, and ensure the output is valid JSON):\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"single\": [\n",
        "    \"string\"\n",
        "  ],\n",
        "  \"chain\": [\n",
        "    {{\n",
        "      \"full_commands\": \"string\",\n",
        "      \"sub_commands\": [\"string\"]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "GENERATED_NUM = 10\n",
        "\n",
        "CHAIN_LENGTH = 3\n",
        "\n",
        "\n",
        "# gpt-4o-mini\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key = api_key)\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "\n",
        "TEMPERATURE = 1\n",
        "\n",
        "\n",
        "# Sampling Args\n",
        "NUM_SAMPLES_COMMAND = 20\n",
        "\n",
        "NUM_SAMPLES_CONTENT = 20"
      ],
      "metadata": {
        "id": "Ydgsi8nRHF3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def content_sample(num_samples: int):\n",
        "  '''\n",
        "  Sampling num_samples/2 songs, num_samples/2 movies, and all apps in app list.\n",
        "\n",
        "  Args:\n",
        "    int: num_samples -> number of samples that add to prompt\n",
        "\n",
        "  Returns:\n",
        "    song_list (list): list of songs\n",
        "    movie_list (list): list of movies\n",
        "    app_list (list): list of apps\n",
        "  '''\n",
        "  num_songs = num_samples//2\n",
        "  num_movies = num_samples - num_songs\n",
        "  song_sample = song_dataset.sample(num_songs).reset_index(drop = True)\n",
        "  movie_sample = movie_dataset.sample(num_movies).reset_index(drop = True)\n",
        "\n",
        "  song_list = [f\"artist: {song_sample.iloc[i]['artist']}- song: {song_sample.iloc[i]['song']}\" for i in range(num_songs)]\n",
        "  movie_list = [f\"movie: {movie_sample.iloc[i]['Title']}\" for i in range(num_movies)]\n",
        "  app_list = [f\"app: {app_dataset[i]}\" for i in range(len(app_dataset))]\n",
        "  return song_list, movie_list, app_list\n",
        "\n",
        "def command_sample(num_samples: int):\n",
        "  '''\n",
        "  Sampling num_samples commands from tv_command_templates.\n",
        "\n",
        "  Args:\n",
        "    int: num_samples -> number of samples that add to prompt\n",
        "\n",
        "  Returns:\n",
        "    samples (list): list of commands\n",
        "  '''\n",
        "  samples = random.sample(tv_command_templates, num_samples)\n",
        "  return samples\n",
        "\n",
        "def generate(command_list: list, content_list: list, generated_num: int = GENERATED_NUM, chain_length: int = CHAIN_LENGTH):\n",
        "  '''\n",
        "  Create a prompt then feed to model to generate json of synthesized commands\n",
        "\n",
        "  Args:\n",
        "\n",
        "  Returns:\n",
        "  '''\n",
        "  prompt = prompt_template.format(command_list=command_list, content_list = content_list, generated_nums=generated_num, chain_length=chain_length)\n",
        "  response = client.responses.create(\n",
        "      model = MODEL,\n",
        "      input = prompt,\n",
        "      temperature = TEMPERATURE,\n",
        "  )\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "AeeJ4QTNGUwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 function for json parsing\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "def clean_json_string(raw_output):\n",
        "    # Bỏ phần ```json và ```\n",
        "    cleaned = re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw_output.strip())\n",
        "    return cleaned\n",
        "\n",
        "def parse_generated_json(raw_output):\n",
        "    cleaned = clean_json_string(raw_output)\n",
        "    return json.loads(cleaned)\n"
      ],
      "metadata": {
        "id": "-VOEq-kk155F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create pandas from json\n",
        "def create_df(parsed_data, export_name = None):\n",
        "  data = parsed_data\n",
        "  rows = []\n",
        "\n",
        "  # single command processing\n",
        "  for idx, cmd in enumerate(data['single']):\n",
        "      rows.append({\n",
        "          'command': cmd,\n",
        "          'type': 'single',\n",
        "          'sub_command': None\n",
        "      })\n",
        "\n",
        "  # chain of commands processing\n",
        "  for i, cmd in enumerate(data['chain']):\n",
        "      row_id = f\"chain_{i:08d}\"\n",
        "      rows.append({\n",
        "          'command': cmd['full_commands'],\n",
        "          'type': 'chain',\n",
        "          'sub_command': cmd['sub_commands']\n",
        "      })\n",
        "\n",
        "  # create dataframes\n",
        "  df = pd.DataFrame(rows)\n",
        "\n",
        "  if export_name is not None:\n",
        "    df.to_csv(f'{export_name}.csv', index=False)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ZzOkgvNQ2OXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "uicRfkmd1rEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # thêm tqdm\n",
        "\n",
        "list_commands = []\n",
        "\n",
        "num = 100 # num * generated num\n",
        "for i in tqdm(range(50)):  # thêm progress bar\n",
        "    # command sampling\n",
        "    command_list = command_sample(num_samples=NUM_SAMPLES_COMMAND)\n",
        "\n",
        "    # content sampling\n",
        "    song_list, movie_list, app_list = content_sample(num_samples=NUM_SAMPLES_CONTENT)\n",
        "\n",
        "    # content list\n",
        "    content_list = song_list + movie_list + app_list  # list of all content\n",
        "\n",
        "    # create commands\n",
        "    response = generate(command_list, content_list)\n",
        "\n",
        "    # get the content (commands in json form)\n",
        "    raw_output = response.output[0].content[0].text\n",
        "\n",
        "    # Parse commands json\n",
        "    json_commands = parse_generated_json(raw_output)\n",
        "\n",
        "    # create dataframe\n",
        "    df_commands = create_df(parsed_data=json_commands, export_name='commands')\n",
        "\n",
        "    list_commands.append(df_commands)\n"
      ],
      "metadata": {
        "id": "qDVH8p4uIny-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_commands"
      ],
      "metadata": {
        "id": "DwiCNg47R40x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_commands_df = pd.concat(list_commands, ignore_index=True)"
      ],
      "metadata": {
        "id": "315YSEu4NMJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_commands_df.to_csv('commands.csv', index=False)"
      ],
      "metadata": {
        "id": "-b1svkbvT4U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Synthesis\n",
        "Return:\n",
        "-"
      ],
      "metadata": {
        "id": "wyVTKVvlwDv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model T5 Init"
      ],
      "metadata": {
        "id": "ZDuqBEGBdVky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.resources import files\n",
        "from f5_tts.api import F5TTS\n",
        "\n",
        "f5tts = F5TTS(device = 'cuda')"
      ],
      "metadata": {
        "id": "t_b7rCTrnBR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "ugbS3rsTwKsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_generate(command: str, model = f5tts, ref_file: str = \"\", ref_text: str = \"\"):\n",
        "  '''\n",
        "  generate speech command with model f5tts\n",
        "  '''\n",
        "  wav, sr, spec = model.infer(\n",
        "      ref_file=ref_file,\n",
        "      ref_text=ref_text,\n",
        "      gen_text=command,\n",
        "      seed=None,\n",
        "  )\n",
        "  return wav, sr, spec\n",
        "\n",
        "def ref_sample(audio_folder_path, json_folder_path):\n",
        "  '''\n",
        "  sampling reference (audio and text)\n",
        "\n",
        "  Returns:\n",
        "  - id: id of reference (for tracing)\n",
        "  - ref_speech_path: path of reference audio\n",
        "  - ref_text_path: path of reference text\n",
        "\n",
        "  '''\n",
        "\n",
        "  # list for sampling\n",
        "  audio_files = os.listdir(audio_folder_path)\n",
        "  json_files = os.listdir(json_folder_path)\n",
        "\n",
        "  # sampling\n",
        "  audio_file = random.choice(audio_files)\n",
        "  json_file = random.choice(json_files)\n",
        "\n",
        "  # get ID\n",
        "  id = json_file.split(\".\")[0]\n",
        "\n",
        "  # get ref path\n",
        "  ref_speech_path = os.path.join(audio_folder_path, audio_file)\n",
        "  ref_text_path = os.path.join(json_folder_path, json_file)\n",
        "\n",
        "  return id, ref_speech_path, ref_text_path"
      ],
      "metadata": {
        "id": "swDgj-3KwUPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def audio_pipeline(dataset, ref_speech_folder: str = \"/content/audio/dung\",\n",
        "                            ref_meta_folder: str = \"/content/json/dung\"):\n",
        "    results = {}\n",
        "\n",
        "    for idx in range(len(dataset)):\n",
        "        # get command for sampling\n",
        "        sample = dataset.iloc[idx]\n",
        "        id = sample['id']\n",
        "\n",
        "        # sampling reference\n",
        "        ref_id, ref_file, ref_text = ref_sample(audio_folder_path = ref_speech_folder, json_folder_path =  ref_meta_folder)\n",
        "\n",
        "        # Single Case\n",
        "        if sample['type'] == 'single':\n",
        "\n",
        "            # single command\n",
        "            command = sample['command']\n",
        "\n",
        "            # synthesis\n",
        "            wav, sr, spec = audio_generate(command, ref_file=ref_file, ref_text=ref_text)\n",
        "\n",
        "            results[id] = {\n",
        "                'ref_id': ref_id,\n",
        "                'ref_file': ref_file,\n",
        "                'ref_text': ref_text,\n",
        "                'type': 'single',\n",
        "                'command': command,\n",
        "                'wav': wav,\n",
        "                'sr': sr,\n",
        "                'spec': spec,\n",
        "                'sub_commands': None\n",
        "            }\n",
        "\n",
        "        elif sample['type'] == 'chain':\n",
        "            # full command synthesis\n",
        "            command = sample['command']\n",
        "            wav, sr, spec = audio_generate(command, ref_file=ref_file, ref_text=ref_text)\n",
        "\n",
        "            # sub commands synthesis\n",
        "            sub_commands = sample['sub_command']\n",
        "            dict_sub_commands = {}\n",
        "\n",
        "            for sub_idx, sub_cmd in enumerate(sub_commands):\n",
        "                wav, sr, spec = audio_generate(sub_cmd, ref_file=ref_file, ref_text=ref_text)\n",
        "                dict_sub_commands[str(sub_idx)] = {\n",
        "                    'command': sub_cmd,\n",
        "                    'wav': wav,\n",
        "                    'sr': sr,\n",
        "                    'spec': spec\n",
        "                }\n",
        "\n",
        "            results[id] = {\n",
        "                'ref_id': ref_id,\n",
        "                'ref_file': ref_file,\n",
        "                'ref_text': ref_text,\n",
        "                'type': 'chain',\n",
        "                'command': command,\n",
        "                'wav': wav,\n",
        "                'sr': sr,\n",
        "                'spec': spec,\n",
        "                'sub_commands': dict_sub_commands\n",
        "            }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "KzyWov9P5-4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import soundfile as sf  # pip install soundfile\n",
        "\n",
        "def export_results(results, export_dir='exported_audio'):\n",
        "    # init folder for audio and json\n",
        "    audio_dir = os.path.join(export_dir, 'audio')\n",
        "    json_dir = os.path.join(export_dir, 'json')\n",
        "\n",
        "    os.makedirs(audio_dir, exist_ok=True)\n",
        "    os.makedirs(json_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    # export each file from waveform\n",
        "    for id, data in results.items():\n",
        "        # Export main wav\n",
        "        wav_path = os.path.join(audio_dir, f\"{id}.wav\")\n",
        "        sf.write(wav_path, data['wav'], data['sr'])\n",
        "\n",
        "        # Export metadata json\n",
        "        json_data = {\n",
        "            'id': id,\n",
        "            'ref_id': data['ref_id'],\n",
        "            'ref_file': data['ref_file'],\n",
        "            'ref_text': data['ref_text'],\n",
        "            'type': data['type'],\n",
        "            'command': data['command'],\n",
        "            'sampling_rate': data['sr']\n",
        "        }\n",
        "\n",
        "        # add sub_commands to json\n",
        "        if data['type'] == 'chain':\n",
        "            json_data['sub_commands'] = {\n",
        "                k: {'command': v['command']} for k, v in data['sub_commands'].items()\n",
        "            }\n",
        "\n",
        "        # create json_file\n",
        "        json_path = os.path.join(json_dir, f\"{id}.json\")\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # Export sub_commands wavs if chain\n",
        "        if data['type'] == 'chain':\n",
        "            for k, v in data['sub_commands'].items():\n",
        "                sub_wav_path = os.path.join(audio_dir, f\"{id}_sub{k}.wav\")\n",
        "                sf.write(sub_wav_path, v['wav'], v['sr'])"
      ],
      "metadata": {
        "id": "vjFKJEJb6ETF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main\n",
        "- synthesis_folder with generated command: wav and meta (json)"
      ],
      "metadata": {
        "id": "tBP9I1ye79_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = audio_pipeline(df_commands)\n",
        "\n",
        "export_results(res, 'synthesis_folder')"
      ],
      "metadata": {
        "id": "4nvQDzc41hgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oajEpTMsy6X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOISE Synthesis"
      ],
      "metadata": {
        "id": "nKzn3Dsm_KTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List noise data"
      ],
      "metadata": {
        "id": "3txhjSAf9DJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.openslr.org/resources/17/musan.tar.gz && echo \"Downloaded.\"\n",
        "!tar -xzf musan.tar.gz > /dev/null 2>&1 && echo \"Extracted.\"\n"
      ],
      "metadata": {
        "id": "wYd9qxklKiD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "_JROKJHo9JQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "j5-MZBeFF5Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# get list of sample paths for noise sampling\n",
        "def get_list_samples(folder_path: str = \"/content/musan\"):\n",
        "  wav_files = []\n",
        "\n",
        "  for root, dirs, files in os.walk(folder_path):\n",
        "      for file in files:\n",
        "          if file.endswith(\".wav\"):\n",
        "              wav_files.append(os.path.join(root, file))\n",
        "  return wav_files"
      ],
      "metadata": {
        "id": "QUwMXsZINEIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import soundfile as sf\n",
        "\n",
        "def noise_sampling(duration: float, list_noise: list, volume: float =0.3):\n",
        "    '''\n",
        "    Sample a noise segment of length `noise_length_sec` (in seconds) from a list of noise files.\n",
        "    The process will loop until it finds a noise file longer than the required length.\n",
        "\n",
        "    Args:\n",
        "        duration (float): Length of the desired noise segment (in seconds)\n",
        "        list_noise (list): List of noise file paths\n",
        "        volume (float): Volume adjustment factor (0.0 - 1.0)\n",
        "\n",
        "    Returns:\n",
        "        segment (np.ndarray): The volume-adjusted noise segment\n",
        "        sr (int): Sample rate\n",
        "        noise_path (str): Path of the selected noise file\n",
        "    '''\n",
        "    # count for stop\n",
        "    count = 0\n",
        "\n",
        "\n",
        "    while count < 50:\n",
        "\n",
        "        # sampling a noise_path\n",
        "        noise_path = random.choice(list_noise)\n",
        "\n",
        "        # get wav and sampling rate\n",
        "        noise, sr = sf.read(noise_path)\n",
        "\n",
        "        # get noise_length (number of frames) = duration * sampling_rate\n",
        "        noise_length = int(duration * sr)\n",
        "\n",
        "\n",
        "        # sampling a segment from full noise\n",
        "        if len(noise) >= noise_length:\n",
        "\n",
        "            # (start, end) of sengment\n",
        "            start = random.randint(0, len(noise) - noise_length)\n",
        "            segment = noise[start:start + noise_length]\n",
        "\n",
        "            # rescaling volume for noise\n",
        "            segment = segment * volume\n",
        "            return segment, sr, noise_path\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    raise ValueError(\"Không tìm thấy file noise có độ dài lớn hơn yêu cầu.\")\n"
      ],
      "metadata": {
        "id": "s5DDn5400C1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Noise methods\n",
        "- 3 methods: pad, overlap, middle"
      ],
      "metadata": {
        "id": "6688h4nxF9TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "def resample_audio(audio: np.ndarray, original_sr: int, target_sr: int):\n",
        "    if original_sr == target_sr:\n",
        "        return audio\n",
        "    return librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)\n",
        "\n",
        "def process_noise_segment(position: str, current_time: float, min_noise_len: float, max_noise_len: float, fixed_sr: int, list_noise: list):\n",
        "    \"\"\"\n",
        "    Helper function to sample, resample, and return a noise segment with its metadata.\n",
        "    \"\"\"\n",
        "    noise_length_sec = random.randint(min_noise_len, max_noise_len)\n",
        "    seg, noise_sr, noise_path = noise_sampling(noise_length_sec, list_noise)\n",
        "    seg = resample_audio(seg, noise_sr, fixed_sr)\n",
        "\n",
        "    duration = len(seg) / fixed_sr\n",
        "    noise_range = {\n",
        "        \"start\": current_time,\n",
        "        \"end\": current_time + duration\n",
        "    }\n",
        "    noise_file = {\n",
        "        \"file\": noise_path,\n",
        "        \"type\": position,\n",
        "        \"sampling_rate\": fixed_sr\n",
        "    }\n",
        "\n",
        "    return seg, noise_range, noise_file, duration\n",
        "\n",
        "def pad_noise(file_path: str, min_noise_len: float = 2, max_noise_len: float = 10, fixed_sr=16000, list_noise=None):\n",
        "    '''\n",
        "    Pad noise to beginning, end, or both sides of an audio file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): path to the original audio file\n",
        "        min_noise_len (float): minimum length of noise in seconds\n",
        "        max_noise_len (float): maximum length of noise in seconds\n",
        "        fixed_sr (int): target sample rate to resample all audio\n",
        "        list_noise (list): list of noise audio files\n",
        "\n",
        "    Returns:\n",
        "        audio_out (np.ndarray): audio with added noise\n",
        "        sr (int): sample rate (always equals fixed_sr)\n",
        "        meta_template (dict): metadata containing positions of noise and original segments\n",
        "    '''\n",
        "    if list_noise is None:\n",
        "        raise ValueError(\"list_noise must be provided for sampling\")\n",
        "\n",
        "    # Load and resample the original audio\n",
        "    audio, sr = sf.read(file_path)\n",
        "    audio = resample_audio(audio, sr, fixed_sr)\n",
        "    sr = fixed_sr\n",
        "\n",
        "    pad_mode = random.choice([\"before\", \"after\", \"both\"])\n",
        "\n",
        "    noise_ranges = []\n",
        "    noise_files = []\n",
        "    total_audio = []\n",
        "    current_time = 0.0\n",
        "\n",
        "    # Padding before\n",
        "    if pad_mode in [\"before\", \"both\"]:\n",
        "        seg, noise_range, noise_file, duration = process_noise_segment(\n",
        "            position=\"before\",\n",
        "            current_time=current_time,\n",
        "            min_noise_len=min_noise_len,\n",
        "            max_noise_len=max_noise_len,\n",
        "            fixed_sr=fixed_sr,\n",
        "            list_noise=list_noise\n",
        "        )\n",
        "        total_audio.append(seg)\n",
        "        noise_ranges.append(noise_range)\n",
        "        noise_files.append(noise_file)\n",
        "        current_time += duration\n",
        "\n",
        "    # Original audio\n",
        "    audio_length_sec = len(audio) / fixed_sr\n",
        "    total_audio.append(audio)\n",
        "    label_range = {\n",
        "        \"start\": current_time,\n",
        "        \"end\": current_time + audio_length_sec,\n",
        "        \"label\": 1\n",
        "    }\n",
        "    current_time += audio_length_sec\n",
        "\n",
        "    # Padding after\n",
        "    if pad_mode in [\"after\", \"both\"]:\n",
        "        seg, noise_range, noise_file, duration = process_noise_segment(\n",
        "            position=\"after\",\n",
        "            current_time=current_time,\n",
        "            min_noise_len=min_noise_len,\n",
        "            max_noise_len=max_noise_len,\n",
        "            fixed_sr=fixed_sr,\n",
        "            list_noise=list_noise\n",
        "        )\n",
        "        total_audio.append(seg)\n",
        "        noise_ranges.append(noise_range)\n",
        "        noise_files.append(noise_file)\n",
        "        current_time += duration\n",
        "\n",
        "    # Combine all\n",
        "    audio_out = np.concatenate(total_audio)\n",
        "    audio_duration = len(audio_out) / fixed_sr\n",
        "\n",
        "    meta_template = {\n",
        "        \"label_range\": [label_range],\n",
        "        \"noise_range\": noise_ranges,\n",
        "        \"noise_file\": noise_files,\n",
        "        \"duration\": audio_duration,\n",
        "    }\n",
        "\n",
        "    return audio_out, fixed_sr, meta_template\n"
      ],
      "metadata": {
        "id": "ZSgN6MVhQCmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "def overlap_noise(file: str,\n",
        "                  list_noise=None,\n",
        "                  noise_volume: float = 0.3,\n",
        "                  min_overlap_ratio: float = 0.5,\n",
        "                  max_overlap_ratio: float = 1.5,\n",
        "                  fixed_sr: int = 16000):\n",
        "    '''\n",
        "    Randomly overlaps a segment of noise on the original audio, potentially exceeding its original duration.\n",
        "    All audio will be resampled to fixed_sr.\n",
        "\n",
        "    Args:\n",
        "        file (str): Path to the original audio file\n",
        "        list_noise (list): List of paths to noise audio files\n",
        "        noise_volume (float): Volume scale of the noise (0.0 - 1.0)\n",
        "        min_overlap_ratio (float): Minimum ratio of noise length to original audio\n",
        "        max_overlap_ratio (float): Maximum ratio of noise length to original audio\n",
        "        fixed_sr (int): Target sample rate to resample both original and noise audio\n",
        "\n",
        "    Returns:\n",
        "        audio_out (np.ndarray): Audio with overlapped noise\n",
        "        sr (int): Sample rate (equal to fixed_sr)\n",
        "        meta_template (dict): Metadata containing positions of the original and noise segments\n",
        "    '''\n",
        "    if list_noise is None:\n",
        "        raise ValueError(\"list_noise must be provided for sampling\")\n",
        "\n",
        "    # Load and resample original audio\n",
        "    audio, sr = sf.read(file)\n",
        "    audio = resample_audio(audio, sr, fixed_sr)\n",
        "    sr = fixed_sr\n",
        "\n",
        "    audio_length = len(audio)\n",
        "    audio_length_sec = audio_length / sr\n",
        "\n",
        "    # Randomly determine noise length\n",
        "    overlap_ratio = random.uniform(min_overlap_ratio, max_overlap_ratio)\n",
        "\n",
        "    noise_length_samples = int(audio_length * overlap_ratio)\n",
        "\n",
        "    noise_length_sec = noise_length_samples / sr\n",
        "\n",
        "    # Sample and resample noise\n",
        "    noise_seg, noise_sr, noise_path = noise_sampling(noise_length_sec, list_noise, volume=noise_volume)\n",
        "    noise_seg = resample_audio(noise_seg, noise_sr, fixed_sr)\n",
        "\n",
        "    # Ensure exact noise length\n",
        "    if len(noise_seg) > noise_length_samples:\n",
        "        noise_seg = noise_seg[:noise_length_samples]\n",
        "    elif len(noise_seg) < noise_length_samples:\n",
        "        noise_seg = np.concatenate([noise_seg, np.zeros(noise_length_samples - len(noise_seg))])\n",
        "\n",
        "    # Randomly choose start position such that noise overlaps with original audio\n",
        "    min_start = -noise_length_samples + 1\n",
        "    max_start = audio_length - 1\n",
        "    start_sample = random.randint(min_start, max_start)\n",
        "    end_sample = start_sample + noise_length_samples\n",
        "\n",
        "    # Pad audio if necessary\n",
        "    padded_audio = audio\n",
        "    if start_sample < 0:\n",
        "        pad_before = -start_sample\n",
        "        padded_audio = np.concatenate([np.zeros(pad_before), padded_audio])\n",
        "        start_sample = 0\n",
        "        end_sample = start_sample + noise_length_samples\n",
        "\n",
        "    if end_sample > len(padded_audio):\n",
        "        pad_after = end_sample - len(padded_audio)\n",
        "        padded_audio = np.concatenate([padded_audio, np.zeros(pad_after)])\n",
        "\n",
        "    # Mix noise\n",
        "    audio_out = padded_audio.copy()\n",
        "    audio_out[start_sample:end_sample] += noise_seg\n",
        "    audio_out = np.clip(audio_out, -1.0, 1.0)\n",
        "\n",
        "    # Metadata\n",
        "    meta_template = {\n",
        "        \"label_range\": [{\n",
        "            \"start\": 0.0,\n",
        "            \"end\": audio_length_sec,\n",
        "            \"label\": 1\n",
        "        }],\n",
        "        \"noise_range\": [{\n",
        "            \"start\": start_sample / sr,\n",
        "            \"end\": end_sample / sr\n",
        "        }],\n",
        "        \"noise_file\": [{\n",
        "            \"file\": noise_path,\n",
        "            \"type\": \"overlap\"\n",
        "        }],\n",
        "        \"duration\": len(audio_out) / sr\n",
        "    }\n",
        "\n",
        "    return audio_out, sr, meta_template\n"
      ],
      "metadata": {
        "id": "U96sWJdnTrEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "def middle_noise(files,\n",
        "                 list_noise=None,\n",
        "                 noise_volume: float = 0.3,\n",
        "                 fixed_sr: int = 16000):\n",
        "    '''\n",
        "    Concatenates audio files and inserts noise segments in between them (with optional overlap).\n",
        "    All audio will be resampled to fixed_sr.\n",
        "\n",
        "    Args:\n",
        "        files (list of str): List of paths to audio files\n",
        "        list_noise (list of str): List of paths to noise audio files\n",
        "        noise_volume (float): Volume scaling factor for noise (0.0 - 1.0)\n",
        "        fixed_sr (int): Target sample rate to resample all audio\n",
        "\n",
        "    Returns:\n",
        "        audio_out (np.ndarray): Final audio with inserted noises\n",
        "        sr (int): Sample rate (equal to fixed_sr)\n",
        "        meta_template (dict): Metadata including label and noise segments\n",
        "    '''\n",
        "    if not list_noise:\n",
        "        raise ValueError(\"list_noise must be provided\")\n",
        "\n",
        "    total_audio = []\n",
        "    label_ranges = []\n",
        "    noise_ranges = []\n",
        "    noise_files = []\n",
        "\n",
        "    current_time = 0.0  # in seconds\n",
        "\n",
        "    for idx, file_path in enumerate(files):\n",
        "        # Load and resample original audio\n",
        "        audio, sr = sf.read(file_path)\n",
        "        audio = resample_audio(audio, sr, fixed_sr)\n",
        "        sr = fixed_sr\n",
        "        audio_length_sec = len(audio) / sr\n",
        "\n",
        "        # Label range for this segment\n",
        "        label_ranges.append({\n",
        "            \"start\": current_time,\n",
        "            \"end\": current_time + audio_length_sec,\n",
        "            \"label\": 1\n",
        "        })\n",
        "\n",
        "        total_audio.append(audio)\n",
        "        current_time += audio_length_sec\n",
        "\n",
        "        # Insert noise between segments\n",
        "        if idx < len(files) - 1:\n",
        "            # Random noise duration: 0.5 - 2.0 seconds\n",
        "            noise_length_sec = random.uniform(0.5, 2.0)\n",
        "            noise_seg, noise_sr, noise_path = noise_sampling(noise_length_sec, list_noise, volume=noise_volume)\n",
        "            noise_seg = resample_audio(noise_seg, noise_sr, fixed_sr)\n",
        "\n",
        "            # Optional overlap with previous segment\n",
        "            overlap_ratio = random.uniform(0.0, 0.5)\n",
        "            overlap_samples = int(overlap_ratio * len(noise_seg))\n",
        "\n",
        "            if overlap_samples > 0:\n",
        "                prev_audio = total_audio[-1]\n",
        "                # Pad if necessary\n",
        "                if len(prev_audio) < overlap_samples:\n",
        "                    prev_audio = np.pad(prev_audio, (0, overlap_samples - len(prev_audio)))\n",
        "                prev_audio[-overlap_samples:] += noise_seg[:overlap_samples]\n",
        "                prev_audio = np.clip(prev_audio, -1.0, 1.0)\n",
        "                total_audio[-1] = prev_audio\n",
        "                total_audio.append(noise_seg[overlap_samples:])\n",
        "            else:\n",
        "                total_audio.append(noise_seg)\n",
        "\n",
        "            # Update metadata\n",
        "            noise_start_sec = current_time - (overlap_samples / sr)\n",
        "            noise_end_sec = noise_start_sec + (len(noise_seg) / sr)\n",
        "\n",
        "            noise_ranges.append({\n",
        "                \"start\": noise_start_sec,\n",
        "                \"end\": noise_end_sec\n",
        "            })\n",
        "            noise_files.append({\n",
        "                \"file\": noise_path,\n",
        "                \"type\": \"middle\"\n",
        "            })\n",
        "\n",
        "            current_time = noise_end_sec\n",
        "\n",
        "    # Final concatenated output\n",
        "    audio_out = np.concatenate(total_audio)\n",
        "    audio_out = np.clip(audio_out, -1.0, 1.0)\n",
        "\n",
        "    meta_template = {\n",
        "        \"label_range\": label_ranges,\n",
        "        \"noise_range\": noise_ranges,\n",
        "        \"noise_file\": noise_files,\n",
        "        \"duration\": len(audio_out) / sr\n",
        "    }\n",
        "\n",
        "    return audio_out, sr, meta_template"
      ],
      "metadata": {
        "id": "qoGzSgIlVcZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('commands.csv')"
      ],
      "metadata": {
        "id": "kMTfkhjtM2tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flow"
      ],
      "metadata": {
        "id": "oQgKaoKhGsbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import ast\n",
        "\n",
        "def data_synthesis(commands_path: str = '/content/commands.csv',\n",
        "                   export_folder: str = 'content/data_synthesis_with_noise',\n",
        "                   command_audio_path: str = '/content/synthesis_folder/audio',\n",
        "                   noise_folder: str = '/content/musan') -> pd.DataFrame:\n",
        "\n",
        "    list_noise = get_list_samples(noise_folder)\n",
        "\n",
        "    # create folders\n",
        "    audio_folder = os.path.join(export_folder, 'audio')\n",
        "    meta_folder = os.path.join(export_folder, 'meta')\n",
        "    os.makedirs(audio_folder, exist_ok=True)\n",
        "    os.makedirs(meta_folder, exist_ok=True)\n",
        "\n",
        "    # read command csv\n",
        "    df = pd.read_csv(commands_path)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        base_name = f\"{row['id']}\"\n",
        "        command_audio_file = os.path.join(command_audio_path, row['id'])\n",
        "\n",
        "        # Single Case\n",
        "        choice = ['pad', 'overlap']\n",
        "        selected = random.choice(choice)\n",
        "\n",
        "        if selected == 'pad':\n",
        "            audio, sr, meta = pad_noise(command_audio_file + '.wav', list_noise = list_noise)\n",
        "        elif selected == 'overlap':\n",
        "            audio, sr, meta = overlap_noise(command_audio_file + '.wav', list_noise = list_noise)\n",
        "\n",
        "        name = f\"{base_name}_{selected}\"\n",
        "        audio_path = os.path.join(audio_folder, f\"{name}.wav\")\n",
        "        meta_path = os.path.join(meta_folder, f\"{name}.json\")\n",
        "\n",
        "        sf.write(audio_path, audio, sr)\n",
        "        with open(meta_path, 'w') as f:\n",
        "            json.dump(meta, f, indent=2)\n",
        "\n",
        "        results.append({\n",
        "            \"id\": row[\"id\"],\n",
        "            \"type\": row[\"type\"],\n",
        "            \"variation\": selected,\n",
        "            \"audio_path\": audio_path,\n",
        "            \"meta_path\": meta_path\n",
        "        })\n",
        "\n",
        "        # Chain Case\n",
        "        if row['type'] == 'chain':\n",
        "            try:\n",
        "                sub_commands_id = [f\"{row['id']}_sub{i}\" for i in range(len(ast.literal_eval(row['sub_command'])))]\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing sub_command at row {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "            list_sub_command_path = [os.path.join(command_audio_path, sc + '.wav') for sc in sub_commands_id]\n",
        "            audio, sr, meta = middle_noise(list_sub_command_path, list_noise = list_noise)\n",
        "\n",
        "            name = f\"{base_name}_middle\"\n",
        "            audio_path = os.path.join(audio_folder, f\"{name}.wav\")\n",
        "            meta_path = os.path.join(meta_folder, f\"{name}.json\")\n",
        "\n",
        "            sf.write(audio_path, audio, sr)\n",
        "            with open(meta_path, 'w') as f:\n",
        "                json.dump(meta, f, indent=2)\n",
        "\n",
        "            results.append({\n",
        "                \"id\": row[\"id\"],\n",
        "                \"type\": row[\"type\"],\n",
        "                \"variation\": \"middle\",\n",
        "                \"audio_path\": audio_path,\n",
        "                \"meta_path\": meta_path\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "iAayKy48Gtzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "qDeTHwAqGB1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthesis_df = data_synthesis()"
      ],
      "metadata": {
        "id": "IkvQeuvWNI6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthesis_df"
      ],
      "metadata": {
        "id": "Iw68AuQ8Nd7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r synthesis_data_with_noise.zip /content/content/data_synthesis_with_noise\n",
        "!zip -r synthesis_folder /content/synthesis_folder"
      ],
      "metadata": {
        "id": "D2UDRadHPaLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO, add noise as SNR"
      ],
      "metadata": {
        "id": "5rYyWifrS-2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}